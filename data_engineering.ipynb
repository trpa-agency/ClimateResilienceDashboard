{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Tahoe region greenhouse gas (GHG) emissions and support the measurement of carbon sequestration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track poor air quality, wildfire smoke, and extreme heat trends regionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake Tahoe water level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065&startDT={start_date_str}&endDT={end_date_str}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual average water temperature, including surface water temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake clarity measured by Secchi Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total precipitation in water per year, extreme precipitation, and snow as a fraction of annual precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres of forest fuels reduction treated for wildfire in high-risk areas, map of prescribed fire treatment projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# EIP Service for Acres Treated\n",
    "eipForestTreatments = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/19\"\n",
    "\n",
    "# get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree species diversity and increasing old growth forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display Old Growth Forest Acres\n",
    "eipOldGrowthForest = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/20\"\n",
    "\n",
    "df = pd.read_json(eipOldGrowthForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of fire by low, moderate, & high severity by management zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial analysis for fire severity\n",
    "import arcpy\n",
    "\n",
    "# reclass Low Severity flame length raster\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\"):\n",
    "    out_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=r\"F:\\\\GIS\\\\PROJECTS\\\\ForestHealth_Intiative\\\\ThresholdUpdate\\\\Data\\\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbLowSeverity_2022_ACCEL_30m_Tahoe\",\n",
    "        reclass_field=\"Value\",\n",
    "        remap=\"0 0.600000 0;0.600000 1 1\",\n",
    "        missing_values=\"DATA\"\n",
    "    )\n",
    "    out_raster.save(r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_Reclass_Low_60thPercentile\")\n",
    "\n",
    "# convert reclassified raster to polygon\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=r\"Fire Severity\\Low Severity Fire\",\n",
    "    out_polygon_features=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbableLowSeverityFire\",\n",
    "    simplify=\"NO_SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")\n",
    "\n",
    "# identity analysis\n",
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"Boundaries\\Forest Management Zone\",\n",
    "    identity_features=\"FunctionalFire_ProbableLowSeverityFire\",\n",
    "    out_feature_class=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")\n",
    "\n",
    "# Calculate the area in acres for each feature\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=r\"Fire Severity\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# export table to database\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=r\"Fire Severity\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_ProbabilityLowSeverityFire_by_ForestManagmentZone\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    sort_field=None\n",
    ")\n",
    "\n",
    "# reclass High Severity flame length raster\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\"):\n",
    "    out_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=r\"F:\\\\GIS\\\\PROJECTS\\\\ForestHealth_Intiative\\\\ThresholdUpdate\\\\Data\\\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbHighSeverity_2022_ACCEL_30m_Tahoe\",\n",
    "        reclass_field=\"Value\",\n",
    "        remap=\"0 0.600000 0;0.600000 1 1\",\n",
    "        missing_values=\"DATA\"\n",
    "    )\n",
    "    out_raster.save(r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_Reclass_High_60thPercentile\")\n",
    "\n",
    "# convert reclassified raster to polygon\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=r\"Fire Severity\\High Severity Fire\",\n",
    "    out_polygon_features=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbableHighSeverityFire\",\n",
    "    simplify=\"NO_SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")\n",
    "\n",
    "# identity analysis\n",
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"Boundaries\\Forest Management Zone\",\n",
    "    identity_features=\"FunctionalFire_ProbableHighSeverityFire\",\n",
    "    out_feature_class=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")\n",
    "\n",
    "# Calculate the area in acres for each feature\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=r\"Fire Severity\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# export table to database\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=r\"Fire Severity\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_ProbabilityHighSeverityFire_by_ForestManagmentZone\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    sort_field=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "highseverityURL = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/129\"\n",
    "lowseverityURL  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/130\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(highseverityURL)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_highseverity = feature_layer.query().sdf\n",
    "\n",
    "sdf_highseverity.head()\n",
    "# summarize the area of high and low severity fire by name and gridcode\n",
    "highseverity_summary = sdf_highseverity.groupby(['Name', 'gridcode'])['Acres'].sum().reset_index()\n",
    "\n",
    "# reclassify values of gridcode in new field called 'Severity' with 1 = \">60% chance of high severity fire\" and 0 = \"<60% chance of high severity fire\"\n",
    "highseverity_summary['Severity'] = np.where(highseverity_summary['gridcode'] == 1, \">60% chance of high severity fire\", \"<60% chance of high severity fire\")\n",
    "\n",
    "# Plot using Plotly Express to create a stacked bar chart of Severity by Name with the bar chart being 100% stacked\n",
    "fig = px.histogram(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barnorm='percent',barmode='stack')\n",
    "# fig = px.bar(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barmode='stack')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowseverityURL  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/130\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(lowseverityURL)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_lowseverity = feature_layer.query().sdf\n",
    "\n",
    "sdf_lowseverity.head()\n",
    "# summarize the area of high and low severity fire by name and gridcode\n",
    "lowseverity_summary = sdf_lowseverity.groupby(['Name', 'gridcode'])['Acres'].sum().reset_index()\n",
    "\n",
    "# reclassify values of gridcode in new field called 'Severity' \n",
    "lowseverity_summary['Severity'] = np.where(lowseverity_summary['gridcode'] == 1, \">60% chance of low severity fire\", \"<60% chance of low severity fire\")\n",
    "\n",
    "# Plot using Plotly Express to create a stacked bar chart of Severity by Name with the bar chart being 100% stacked\n",
    "fig = px.histogram(lowseverity_summary, x='Name', y='Acres', color='Severity', title='Low Severity Fire by Forest Management Zone', barnorm='percent',barmode='stack')\n",
    "# fig = px.bar(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Moderate Severity Fire does not exist in the service....USFS data is needed to complete the analysis, but they didnt provide it in the data package\n",
    "\n",
    "# we could get at this by doing the math's between low and high severity fire, but that would be a bit of a stretch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres treated for aquatic invasive species. *We could gain additional clarity regarding this indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# EIP Service for Acres Treated\n",
    "eipInvasive = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/15\"\n",
    "\n",
    "df = pd.read_json(eipInvasive)\n",
    "\n",
    "sum_df = df.groupby('IndicatorProjectYear')['IndicatorProjectValue'].cumsum()\n",
    "\n",
    "display(sum_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres of restored high-quality wetlands and meadows helping to store flood waters. *We are expecting additional clarity regarding this indicator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# EIP Service for Acres Treated\n",
    "eipSEZRestored = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/9\"\n",
    "\n",
    "df = pd.read_json(eipSEZRestored)\n",
    "\n",
    "sum_df = df.groupby('IndicatorProjectYear')['IndicatorProjectValue'].cumsum()\n",
    "\n",
    "display(sum_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased number of parcels with Stormwater Best Management Practices (BMPs) improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BMP data as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# BMP Service for BMPs Installed\n",
    "bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "# get the data\n",
    "feature_layer = FeatureLayer(bmpsLayer)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bmps = feature_layer.query().sdf\n",
    "\n",
    "# total BMPs installed\n",
    "total_bmps = sdf_bmps['BMP_ID'].count()\n",
    "display(total_bmps)\n",
    "\n",
    "# total Developed Parcels\n",
    "\n",
    "# total BMPs installed per developed parcel\n",
    "\n",
    "# total BMPs installed per developed parcel per year\n",
    "\n",
    "# total BMPs installed per developed parcel per year per BMP type\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase in square feet of urban development treated by areawide stormwater infrastructure within key watersheds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of housing units in town centers and share of affordable housing in Town Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towncenterService               = \"https://maps.trpa.org/server/rest/services/LocalPlan/MapServer/2\"\n",
    "parcelDevelopmentHistoryService = \"https://maps.trpa.org/server/rest/services/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in share of homes with electric or solar energy fuel compared to oil/gas over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of deed-restricted affordable, moderate, and achievable units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# deed restriction service\n",
    "deedRestrictionService = \"https://www.laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\"\n",
    "\n",
    "# read in deed restricted parcels\n",
    "dfDeed = pd.read_json(deedRestrictionService)\n",
    "\n",
    "# filter out deed restrictions that are not affordable housing\n",
    "dfDeed = dfDeed.loc[dfDeed['DeedRestrictionType'].isin(['Affordable Housing', 'Achievable Housing', 'Moderate Income Housing'])]\n",
    "\n",
    "# create year column\n",
    "dfDeed['Year'] = dfDeed['RecordingDate'].str[-4:]\n",
    "\n",
    "# group by type and year\n",
    "df = dfDeed.groupby(['DeedRestrictionType', 'Year']).size().reset_index(name='Total')\n",
    "\n",
    "# sort by year\n",
    "df.sort_values('Year', inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df = df.rename(columns={'DeedRestrictionType': 'Type', 'Year': 'Year', 'Total': 'Count'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Type': np.repeat(df['Type'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Type'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Type', 'Year'], how='left')\n",
    "\n",
    "# Replace NaN values in 'Count' with 0\n",
    "df['Count'] = df['Count'].fillna(0)\n",
    "\n",
    "# Ensure 'Count' is of integer type\n",
    "df['Count'] = df['Count'].astype(int)\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Count'] = df.sort_values('Year').groupby('Type')['Count'].cumsum()\n",
    "\n",
    "# create cumuluative total of deed restricted parcels by type\n",
    "fig = px.line(df, x=\"Year\", y=\"Cumulative Count\", color=\"Type\", title=\"Deed Restricted Parcels\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of renewable energy as a share of total energy used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total transit ridership by transit systems\n",
    "* https://www.laketahoeinfo.org/Indicator/Detail/46/Overview\n",
    "* this doesn't work yet. Talking to ESA to get web service stood up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# indicator #46\n",
    "eipTransit = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/46\"\n",
    "\n",
    "# read in as dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily per capita Vehicles Miles Traveled (VMT) and progress towards VMT target. The RTP (2021) identifies a Daily per capita VMT target set at a 6.8 percent reduction from 2018 levels by 2045 (2018 per capita daily VMT is 12.48, goal is 11.63)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh/RSG?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage of electric bus routes and alternative fuel, such as EV charging for vehicles and bicycles\n",
    "* Primary source: https://www.plugshare.com/ requested access to their API\n",
    "* Secondary (if needed to cross-check): https://afdc.energy.gov/stations/#/find/nearest\n",
    "\n",
    "* current in-house data: https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline mode share and weekday or seasonal variation. The Tahoe RTP (2021) includes the following Non-Auto Mode Share Target: Improve average non-auto mode share calculated from the two most recent TRPA travel survey results; the current performance on target at 24.5% (2018-20 average) up from 18% in 2014-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transportation access in priority communities. The Tahoe RTP (2021) includes a target to increase access to each mode for Priority communities to 100% by 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased lane miles of low-stress bicycle facilities (both bicycle and pedestrian facilities that are considered comfortable enough for all users and abilities, and implicitly measures active transportation network connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "\n",
    "  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Count'] = df.sort_values('Year').groupby('Class')['Miles'].cumsum()\n",
    "\n",
    "# create cumuluative total of miles of bike lanes by Class\n",
    "fig = px.line(df, x=\"Year\", y=\"Cumulative Count\", color=\"Class\", title=\"Miles of Bike Lane by Type\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Household Income (MHI) by community area (to be determined) and disaggregated by remote and non-remote workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing costs (median home sales price and rental rates, by jurisdiction); include cost per unit and cost per square foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing tenure (rented full-time, owner-occupied, second home), disaggregated by race, ethnicity, and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of workers who commute into the basin, origin demographics, distance travelled, difference in travel time by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transient Occupancy Tax revenue and changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD still waiting on Josh to get this data created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent employment and median wages by sector and overall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to recreation sites, fresh food, and healthcare for zero-vehicle households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firewise communities in the Tahoe basin, coolling centers/heating centers, resources, and emergency infrastructure (medical centers with supplies, fire response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population disaggregated by race and ethnicity, age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number/share of households with access and functional needs (These can be referred to as vulnerable populations including populations such as persons with disabilities, older adults, children, limited English proficiency, and transportation disadvantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='lake-level-chart'),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=10 * 1000,  # in milliseconds\n",
    "        n_intervals=0\n",
    "    ),\n",
    "])\n",
    "\n",
    "def get_usgs_data():\n",
    "    # USGS site number for Lake Tahoe\n",
    "    site_number = 10337000\n",
    "    \n",
    "    # USGS API URL for Lake Tahoe site\n",
    "    url = f'https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065'\n",
    "\n",
    "    # Make a request to the USGS API\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract relevant data\n",
    "    time_series_data = data['value']['timeSeries'][0]['values'][0]['value']\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(time_series_data)\n",
    "\n",
    "    # Convert data types\n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "    df['value'] = df['value'] + 6220\n",
    "    return df\n",
    "\n",
    "@app.callback(\n",
    "    Output('lake-level-chart', 'figure'),\n",
    "    [Input('interval-component', 'n_intervals')]\n",
    ")\n",
    "def update_chart(n):\n",
    "    df = get_usgs_data()\n",
    "\n",
    "    # Create a line chart using Plotly Express\n",
    "    fig = px.line(df, x='dateTime', y='value', title='Lake Tahoe Water Level')\n",
    "    fig.update_xaxes(title_text='Time')\n",
    "    fig.update_yaxes(title_text='Water Level (ft)')\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup connection to GIS Portal, this can be and empty GIS() function with a public service\n",
    "gis = GIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature service as a Spatially Enabled Dataframe\n",
    "service_url = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\"\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a Spatially Enabled Dataframe, this brings the SHAPE with it and can be saved back as a spatial file\n",
    "sdfParcels = query_result.sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's an example of a function to get web service data as a regular Pandas dataframe\n",
    "def get_fs_data(service_url):\n",
    "    feature_layer = FeatureLayer(service_url)\n",
    "    query_result = feature_layer.query()\n",
    "    # Convert the query result to a list of dictionaries\n",
    "    feature_list = query_result.features\n",
    "    # Create a pandas DataFrame from the list of dictionaries\n",
    "    all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "    # return data frame\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "feature_list = query_result.features\n",
    "all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PMSubcategoryName3.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "eipSEZ = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/9\"\n",
    "\n",
    "df = pd.read_json(eipSEZ)\n",
    "\n",
    "sum_df = df.groupby('IndicatorProjectYear')['IndicatorProjectValue'].cumsum().reset_index()\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.bar(sum_df, x='IndicatorProjectYear', y='IndicatorProjectValue', title='Sum of Values by Category')\n",
    "fig.show()\n",
    "# fig = px.bar(df, x = \"IndicatorProjectValue\", y = \"IndicatorProjectYear\")\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trpa-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
