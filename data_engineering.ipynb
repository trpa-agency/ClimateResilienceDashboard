{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Tahoe region greenhouse gas (GHG) emissions and support the measurement of carbon sequestration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHG Data\n",
    "ghgTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/124\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track poor air quality, wildfire smoke, and extreme heat trends regionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting Purple Air data\n",
    "\n",
    "# TRPA Air Quality Monitoring data\n",
    "trpaAirqualityStationLayer = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/16\"\n",
    "trpaairqualityDailyTable   = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/17\"\n",
    "trpaairqualityYearlyTable  = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/46\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Purple Air data\n",
    "purpleAirSensorLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/143\"\n",
    "\n",
    "# get data as spatially enabled dataframe from feature layer\n",
    "fl = FeatureLayer(purpleAirSensorLayer)\n",
    "sdfPurpleAir = fl.query().sdf\n",
    "\n",
    "# groupby date and get the mean of pm25\n",
    "sdfPurpleAir = sdfPurpleAir.groupby('date')['mean_pm25'].mean().reset_index()\n",
    "# creat a plotly express line chart\n",
    "fig = px.line(sdfPurpleAir, x=\"date\", y=\"mean_pm25\", title='Purple Air PM2.5')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color background of plotly by x axis value and gradient fill\n",
    "fig = px.line(sdfPurpleAir, x=\"date\", y=\"mean_pm25\", title='Purple Air PM2.5', line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.update_traces(line_color='blue')\n",
    "fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake Tahoe water level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# tahoe city site number\n",
    "site_number = '10337000'\n",
    "\n",
    "# USGS API URL\n",
    "url = f'https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065&startDT=2021-01-01&endDT=2021-01-30'\n",
    "\n",
    "# function to get data from USGS API as dataframe\n",
    "def get_usgs_data(days):\n",
    "    site_number = 10337000\n",
    "    \n",
    "    # Calculate the start and end dates based on the selected time range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    url = f'https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065&startDT={start_date_str}&endDT={end_date_str}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    time_series_data = data['value']['timeSeries'][0]['values'][0]['value']\n",
    "\n",
    "    df = pd.DataFrame(time_series_data)\n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "    df['value'] = df['value'] + 6220\n",
    "    return df\n",
    "\n",
    "# create plot of lake level\n",
    "def update_chart(selected_days):\n",
    "    df = get_usgs_data(selected_days)\n",
    "\n",
    "    fig = px.line(df, x='dateTime', y='value', title='Lake Tahoe Water Level')\n",
    "    fig.update_xaxes(title_text='Time')\n",
    "    fig.update_yaxes(title_text='Water Level (ft)')\n",
    "\n",
    "    return fig\n",
    "\n",
    "# create plot of lake level\n",
    "update_chart(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The USGS Site at Tahoe City only has data for the last 5968 days (~16.3 years) October 2007\n",
    "days = 5968  \n",
    "df = get_usgs_data(days)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual average water temperature, including surface water temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# get data from TERC service\n",
    "lakeTempURL = \"https://tepfsail50.execute-api.us-west-2.amazonaws.com/v1/report/ns-station-range?rptdate=20240130&rptend=20240202&id=4\"\n",
    "# get data from TERC\n",
    "response = requests.get(lakeTempURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake clarity measured by Secchi Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secchi depth data\n",
    "secchiDepth    = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/14\"\n",
    "secchiDepthAll = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/13\"\n",
    "secchiDepth    = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/125\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total precipitation in water per year, extreme precipitation, and snow as a fraction of annual precipitation\n",
    "* https://www.ncei.noaa.gov/cdo-web/\n",
    "* https://www.weather.gov/documentation/services-web-api\n",
    "* https://www.ncdc.noaa.gov/cdo-web/api/v2/\n",
    "\n",
    "##### ended up using \n",
    "* https://cssl.berkeley.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# folder with individual files\n",
    "folder = r\"C:\\Users\\mbindl\\Downloads\\doi_10_6078_D1941T__v20210622\"\n",
    "\n",
    "# create a list to store the data\n",
    "data = []\n",
    "# loop through the files in the folder\n",
    "for file in os.listdir(folder):\n",
    "    # read the file into a DataFrame\n",
    "    df = pd.read_csv(os.path.join(folder, file))\n",
    "    # add the DataFrame to the list\n",
    "    data.append(df)\n",
    "\n",
    "# concatenate the data into a single DataFrame\n",
    "combined_data = pd.concat(data)\n",
    "\n",
    "# change field names to have _ instead of spaces\n",
    "combined_data.columns = combined_data.columns.str.replace(' ', '_')\n",
    "# remove leading and trailing whitespace from field names and change % te Pct\n",
    "combined_data.columns = combined_data.columns.str.strip().str.replace('%', 'Pct')\n",
    "# remove () from field names\n",
    "combined_data.columns = combined_data.columns.str.replace('(', '').str.replace(')', '')\n",
    "# remove - from field names\n",
    "combined_data.columns = combined_data.columns.str.replace('-', '_')\n",
    "# change filed name 24-hour_Total_Precip_mm to Full_Day_Total_Precip_mm\n",
    "combined_data.rename(columns={'24_hour_Total_Precip_mm': 'Full_Day_Total_Precip_mm'}, inplace=True)\n",
    "\n",
    "# make sure all '' are replaced with NaN\n",
    "combined_data = combined_data.replace('', pd.NA)\n",
    "# replace '--' with NaN\n",
    "combined_data = combined_data.replace('--', np.NaN)\n",
    "# replace 'T' in 24_hour_Total_Precip_in with 0\n",
    "combined_data['Full_Day_Total_Precip_mm'] = combined_data['Full_Day_Total_Precip_mm'].replace('T', 0)\n",
    "# replace 'T' and '.' in New_Snow_cm with 0\n",
    "combined_data['New_Snow_cm'] = combined_data['New_Snow_cm'].replace('T', 0)\n",
    "combined_data['New_Snow_cm'] = combined_data['New_Snow_cm'].replace('.', 0)\n",
    "# replace 'T' and '.' in Season_Total_Snow_cm with 0\n",
    "combined_data['Season_Total_Snow_cm'] = combined_data['Season_Total_Snow_cm'].replace('T', 0)\n",
    "# replace 'T' and '.' in Snowpack_depth_cm with 0\n",
    "combined_data['Snowpack_depth_cm'] = combined_data['Snowpack_depth_cm'].replace('T', 0)\n",
    "# replace \"0'0 in Snow_Water_Equivalent_cm with 0\n",
    "combined_data['Snow_Water_Equivalent_cm'] = combined_data['Snow_Water_Equivalent_cm'].replace(\"0'0\", 0)\n",
    "# replace 'T' in Snow_Water_Equivalent_cm with 0\n",
    "combined_data['Snow_Water_Equivalent_cm'] = combined_data['Snow_Water_Equivalent_cm'].replace('T', 0)\n",
    "\n",
    "# convert fields to float\n",
    "combined_data['Pct_of_Precip_as_Snow'] = combined_data['Pct_of_Precip_as_Snow'].astype(float)\n",
    "combined_data['Pct_of_Precip_as_Rain'] = combined_data['Pct_of_Precip_as_Rain'].astype(float)\n",
    "combined_data['Full_Day_Total_Precip_mm'] = combined_data['Full_Day_Total_Precip_mm'].astype(float)\n",
    "combined_data['Air_Temp_Max_C'] = combined_data['Air_Temp_Max_C'].astype(float)\n",
    "combined_data['Air_Temp_Min_C'] = combined_data['Air_Temp_Min_C'].astype(float)\n",
    "combined_data['New_Snow_cm'] = combined_data['New_Snow_cm'].astype(float)\n",
    "combined_data['Season_Total_Snow_cm'] = combined_data['Season_Total_Snow_cm'].astype(float)\n",
    "combined_data['Snowpack_depth_cm'] = combined_data['Snowpack_depth_cm'].astype(float)\n",
    "combined_data['Snow_Water_Equivalent_cm'] = combined_data['Snow_Water_Equivalent_cm'].astype(float)\n",
    "\n",
    "# change Date to datetime\n",
    "combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='mixed', errors='coerce')\n",
    "# add month and year columns\n",
    "combined_data['Month'] = combined_data['Date'].dt.month\n",
    "combined_data['Year'] = combined_data['Date'].dt.year\n",
    "# combined month and year into one column\n",
    "combined_data['Month_Year'] = combined_data['Date'].dt.to_period('M')\n",
    "# combined month and year into one column\n",
    "combined_data['Month_Year'] = combined_data.Month_Year.dt.strftime('%Y-%m')\n",
    "\n",
    "# save to csv\n",
    "combined_data.to_csv(os.path.join(folder,'CentralSierraSnowLab_AllData.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17897 entries, 0 to 364\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Date                      17897 non-null  datetime64[ns]\n",
      " 1   Air_Temp_Max_C            17821 non-null  float64       \n",
      " 2   Air_Temp_Min_C            17832 non-null  float64       \n",
      " 3   Full_Day_Total_Precip_mm  17887 non-null  float64       \n",
      " 4   Season_Total_Precip_mm    17896 non-null  float64       \n",
      " 5   Pct_of_Precip_as_Snow     2606 non-null   float64       \n",
      " 6   Pct_of_Precip_as_Rain     1658 non-null   float64       \n",
      " 7   New_Snow_cm               17640 non-null  float64       \n",
      " 8   Season_Total_Snow_cm      17859 non-null  float64       \n",
      " 9   Snowpack_depth_cm         16161 non-null  float64       \n",
      " 10  Snow_Water_Equivalent_cm  12283 non-null  float64       \n",
      " 11  Remarks                   201 non-null    object        \n",
      " 12  Month                     17897 non-null  int32         \n",
      " 13  Year                      17897 non-null  int32         \n",
      " 14  Month_Year                17897 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(10), int32(2), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Daily_Precip_Rain_mm</th>\n",
       "      <th>Daily_Precip_Snow_mm</th>\n",
       "      <th>Total_Precip_mm</th>\n",
       "      <th>Pct_of_Precip_as_Rain</th>\n",
       "      <th>Pct_of_Precip_as_Snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1987</td>\n",
       "      <td>159.7152</td>\n",
       "      <td>242.8748</td>\n",
       "      <td>402.59</td>\n",
       "      <td>39.671924</td>\n",
       "      <td>60.328076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1988</td>\n",
       "      <td>290.62426</td>\n",
       "      <td>919.43174</td>\n",
       "      <td>1210.056</td>\n",
       "      <td>24.017422</td>\n",
       "      <td>75.982578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1989</td>\n",
       "      <td>533.51938</td>\n",
       "      <td>1042.04262</td>\n",
       "      <td>1575.562</td>\n",
       "      <td>33.862163</td>\n",
       "      <td>66.137837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1990</td>\n",
       "      <td>214.8862</td>\n",
       "      <td>721.4338</td>\n",
       "      <td>936.32</td>\n",
       "      <td>22.950081</td>\n",
       "      <td>77.049919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1991</td>\n",
       "      <td>381.2</td>\n",
       "      <td>1018.8</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>27.228571</td>\n",
       "      <td>72.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1992</td>\n",
       "      <td>455.35</td>\n",
       "      <td>975.65</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>31.820405</td>\n",
       "      <td>68.179595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1993</td>\n",
       "      <td>565.12</td>\n",
       "      <td>1179.88</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>32.3851</td>\n",
       "      <td>67.6149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1994</td>\n",
       "      <td>188.4</td>\n",
       "      <td>1088.6</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>14.753328</td>\n",
       "      <td>85.246672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1995</td>\n",
       "      <td>978.55</td>\n",
       "      <td>1529.63</td>\n",
       "      <td>2508.18</td>\n",
       "      <td>39.014345</td>\n",
       "      <td>60.985655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1996</td>\n",
       "      <td>1283.66</td>\n",
       "      <td>1548.34</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>45.326977</td>\n",
       "      <td>54.673023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1997</td>\n",
       "      <td>397.67</td>\n",
       "      <td>882.33</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>31.067969</td>\n",
       "      <td>68.932031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1998</td>\n",
       "      <td>561.23</td>\n",
       "      <td>1776.67</td>\n",
       "      <td>2337.9</td>\n",
       "      <td>24.005732</td>\n",
       "      <td>75.994268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1999</td>\n",
       "      <td>328.75</td>\n",
       "      <td>1298.25</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>20.2059</td>\n",
       "      <td>79.7941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2000</td>\n",
       "      <td>433.27</td>\n",
       "      <td>1136.73</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>27.596815</td>\n",
       "      <td>72.403185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>242.35</td>\n",
       "      <td>1156.65</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>17.323088</td>\n",
       "      <td>82.676912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2002</td>\n",
       "      <td>425.95</td>\n",
       "      <td>1013.05</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>29.600417</td>\n",
       "      <td>70.399583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2003</td>\n",
       "      <td>294.49</td>\n",
       "      <td>1153.51</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>20.337707</td>\n",
       "      <td>79.662293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2004</td>\n",
       "      <td>227.63</td>\n",
       "      <td>1029.37</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>18.10899</td>\n",
       "      <td>81.89101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2005</td>\n",
       "      <td>1003.87</td>\n",
       "      <td>1079.13</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>48.193471</td>\n",
       "      <td>51.806529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2006</td>\n",
       "      <td>499.48</td>\n",
       "      <td>1302.52</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>27.718091</td>\n",
       "      <td>72.281909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2007</td>\n",
       "      <td>207.86</td>\n",
       "      <td>866.14</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>19.353818</td>\n",
       "      <td>80.646182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2008</td>\n",
       "      <td>287.41</td>\n",
       "      <td>981.59</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>22.648542</td>\n",
       "      <td>77.351458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2009</td>\n",
       "      <td>479.07</td>\n",
       "      <td>986.93</td>\n",
       "      <td>1466.0</td>\n",
       "      <td>32.678718</td>\n",
       "      <td>67.321282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2010</td>\n",
       "      <td>562.18</td>\n",
       "      <td>1663.82</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>25.255166</td>\n",
       "      <td>74.744834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2011</td>\n",
       "      <td>220.97</td>\n",
       "      <td>1038.03</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>17.551231</td>\n",
       "      <td>82.448769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2012</td>\n",
       "      <td>608.42</td>\n",
       "      <td>1068.58</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>36.280262</td>\n",
       "      <td>63.719738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2013</td>\n",
       "      <td>270.68</td>\n",
       "      <td>281.32</td>\n",
       "      <td>552.0</td>\n",
       "      <td>49.036232</td>\n",
       "      <td>50.963768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2014</td>\n",
       "      <td>665.39</td>\n",
       "      <td>708.72</td>\n",
       "      <td>1374.11</td>\n",
       "      <td>48.423343</td>\n",
       "      <td>51.576657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2015</td>\n",
       "      <td>530.47</td>\n",
       "      <td>598.53</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>46.985828</td>\n",
       "      <td>53.014172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016</td>\n",
       "      <td>864.78</td>\n",
       "      <td>1158.22</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>42.747405</td>\n",
       "      <td>57.252595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017</td>\n",
       "      <td>955.17</td>\n",
       "      <td>1693.83</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>36.057758</td>\n",
       "      <td>63.942242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018</td>\n",
       "      <td>531.94</td>\n",
       "      <td>876.06</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>37.77983</td>\n",
       "      <td>62.22017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019</td>\n",
       "      <td>434.46</td>\n",
       "      <td>1440.54</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>23.1712</td>\n",
       "      <td>76.8288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Daily_Precip_Rain_mm  Daily_Precip_Snow_mm  Total_Precip_mm  \\\n",
       "17  1987              159.7152              242.8748           402.59   \n",
       "18  1988             290.62426             919.43174         1210.056   \n",
       "19  1989             533.51938            1042.04262         1575.562   \n",
       "20  1990              214.8862              721.4338           936.32   \n",
       "21  1991                 381.2                1018.8           1400.0   \n",
       "22  1992                455.35                975.65           1431.0   \n",
       "23  1993                565.12               1179.88           1745.0   \n",
       "24  1994                 188.4                1088.6           1277.0   \n",
       "25  1995                978.55               1529.63          2508.18   \n",
       "26  1996               1283.66               1548.34           2832.0   \n",
       "27  1997                397.67                882.33           1280.0   \n",
       "28  1998                561.23               1776.67           2337.9   \n",
       "29  1999                328.75               1298.25           1627.0   \n",
       "30  2000                433.27               1136.73           1570.0   \n",
       "31  2001                242.35               1156.65           1399.0   \n",
       "32  2002                425.95               1013.05           1439.0   \n",
       "33  2003                294.49               1153.51           1448.0   \n",
       "34  2004                227.63               1029.37           1257.0   \n",
       "35  2005               1003.87               1079.13           2083.0   \n",
       "36  2006                499.48               1302.52           1802.0   \n",
       "37  2007                207.86                866.14           1074.0   \n",
       "38  2008                287.41                981.59           1269.0   \n",
       "39  2009                479.07                986.93           1466.0   \n",
       "40  2010                562.18               1663.82           2226.0   \n",
       "41  2011                220.97               1038.03           1259.0   \n",
       "42  2012                608.42               1068.58           1677.0   \n",
       "43  2013                270.68                281.32            552.0   \n",
       "44  2014                665.39                708.72          1374.11   \n",
       "45  2015                530.47                598.53           1129.0   \n",
       "46  2016                864.78               1158.22           2023.0   \n",
       "47  2017                955.17               1693.83           2649.0   \n",
       "48  2018                531.94                876.06           1408.0   \n",
       "49  2019                434.46               1440.54           1875.0   \n",
       "\n",
       "    Pct_of_Precip_as_Rain  Pct_of_Precip_as_Snow  \n",
       "17              39.671924              60.328076  \n",
       "18              24.017422              75.982578  \n",
       "19              33.862163              66.137837  \n",
       "20              22.950081              77.049919  \n",
       "21              27.228571              72.771429  \n",
       "22              31.820405              68.179595  \n",
       "23                32.3851                67.6149  \n",
       "24              14.753328              85.246672  \n",
       "25              39.014345              60.985655  \n",
       "26              45.326977              54.673023  \n",
       "27              31.067969              68.932031  \n",
       "28              24.005732              75.994268  \n",
       "29                20.2059                79.7941  \n",
       "30              27.596815              72.403185  \n",
       "31              17.323088              82.676912  \n",
       "32              29.600417              70.399583  \n",
       "33              20.337707              79.662293  \n",
       "34               18.10899               81.89101  \n",
       "35              48.193471              51.806529  \n",
       "36              27.718091              72.281909  \n",
       "37              19.353818              80.646182  \n",
       "38              22.648542              77.351458  \n",
       "39              32.678718              67.321282  \n",
       "40              25.255166              74.744834  \n",
       "41              17.551231              82.448769  \n",
       "42              36.280262              63.719738  \n",
       "43              49.036232              50.963768  \n",
       "44              48.423343              51.576657  \n",
       "45              46.985828              53.014172  \n",
       "46              42.747405              57.252595  \n",
       "47              36.057758              63.942242  \n",
       "48               37.77983               62.22017  \n",
       "49                23.1712                76.8288  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "# get data from service as spatially enabled dataframe\n",
    "url = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/145\"\n",
    "fl = FeatureLayer(url)\n",
    "sdf = fl.query().sdf\n",
    "\n",
    "# cast Pct_of_Precip_as_Snow to float\n",
    "sdf['Pct_of_Precip_as_Snow'] = sdf['Pct_of_Precip_as_Snow'].astype(float)\n",
    "# cast Pct_of_Precip_as_Rain to float\n",
    "sdf['Pct_of_Precip_as_Rain'] = sdf['Pct_of_Precip_as_Rain'].astype(float)\n",
    "\n",
    "# new field of total snow as water equivalent\n",
    "sdf['Daily_Precip_Rain_mm'] = sdf.Full_Day_Total_Precip_mm * (sdf.Pct_of_Precip_as_Rain/100)\n",
    "sdf['Daily_Precip_Snow_mm'] = sdf.Full_Day_Total_Precip_mm * (sdf.Pct_of_Precip_as_Snow/100)\n",
    "\n",
    "dfYearly = sdf.groupby('Year').agg({'Daily_Precip_Rain_mm': 'sum', 'Daily_Precip_Snow_mm': 'sum'}).reset_index()\n",
    "\n",
    "dfYearly['Total_Precip_mm'] = dfYearly['Daily_Precip_Rain_mm'] + dfYearly['Daily_Precip_Snow_mm']\n",
    "\n",
    "\n",
    "# create percent field for Daily_Precip_Rain_mm by dividing by Full_Day_Total_Precip_mm\n",
    "dfYearly['Pct_of_Precip_as_Rain'] = (dfYearly['Daily_Precip_Rain_mm'] / dfYearly['Total_Precip_mm']) * 100\n",
    "# create percent field for Daily_Precip_Snow_mm by dividing by Full_Day_Total_Precip_mm\n",
    "dfYearly['Pct_of_Precip_as_Snow'] = (dfYearly['Daily_Precip_Snow_mm'] / dfYearly['Total_Precip_mm']) * 100\n",
    "\n",
    "# drop all years before 1987\n",
    "dfYearly = dfYearly[dfYearly['Year'] >= 1987]\n",
    "\n",
    "\n",
    "dfYearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=Pct_of_Precip_as_Rain<br>Year=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Pct_of_Precip_as_Rain",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Pct_of_Precip_as_Rain",
         "offsetgroup": "Pct_of_Precip_as_Rain",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "xaxis": "x",
         "y": [
          39.671924290220815,
          24.017422334172963,
          33.86216346928905,
          22.95008116883117,
          27.22857142857143,
          31.820405310971346,
          32.38510028653295,
          14.753328112764292,
          39.01434506295401,
          45.326977401129945,
          31.067968750000002,
          24.00573163950554,
          20.205900430239705,
          27.596815286624203,
          17.323087919942818,
          29.600416956219593,
          20.337707182320443,
          18.10898965791567,
          48.19347095535286,
          27.718091009988903,
          19.353817504655492,
          22.648542159180458,
          32.6787175989086,
          25.255166217430364,
          17.551231135822082,
          36.28026237328562,
          49.036231884057976,
          48.42334310935805,
          46.98582816651904,
          42.74740484429066,
          36.05775764439411,
          37.779829545454554,
          23.171200000000002
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=Pct_of_Precip_as_Snow<br>Year=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Pct_of_Precip_as_Snow",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Pct_of_Precip_as_Snow",
         "offsetgroup": "Pct_of_Precip_as_Snow",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "xaxis": "x",
         "y": [
          60.32807570977917,
          75.98257766582704,
          66.13783653071094,
          77.04991883116882,
          72.77142857142856,
          68.17959468902865,
          67.61489971346705,
          85.2466718872357,
          60.985654937045986,
          54.673022598870055,
          68.93203125000001,
          75.99426836049446,
          79.79409956976029,
          72.40318471337581,
          82.67691208005718,
          70.3995830437804,
          79.66229281767956,
          81.89101034208431,
          51.80652904464716,
          72.2819089900111,
          80.6461824953445,
          77.35145784081955,
          67.3212824010914,
          74.74483378256963,
          82.44876886417791,
          63.71973762671437,
          50.96376811594203,
          51.576656890641935,
          53.01417183348095,
          57.25259515570934,
          63.942242355605885,
          62.22017045454545,
          76.8288
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "stack",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Percent of Precipitation as Rain vs Snow by Year"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create plotly express bar chart\n",
    "import plotly.express as px\n",
    "\n",
    "# create stacked bar by year of percent of precip as rain vs snow\n",
    "fig = px.bar(dfYearly, x='Year', y=['Pct_of_Precip_as_Rain', 'Pct_of_Precip_as_Snow'], title='Percent of Precipitation as Rain vs Snow by Year')\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the daily data by month and year and get the sum of the daily precip full day total, rain, and snow\n",
    "sdfMonthly = sdf.groupby('Month_Year').agg({'Full_Day_Total_Precip_mm': 'sum', 'Daily_Precip_Rain_mm': 'sum', 'Daily_Precip_Snow_mm': 'sum'}).reset_index()\n",
    "\n",
    "# create percent field for Daily_Precip_Rain_mm by dividing by Full_Day_Total_Precip_mm\n",
    "sdfMonthly['Pct_of_Precip_as_Rain'] = (sdfMonthly['Daily_Precip_Rain_mm'] / sdfMonthly['Full_Day_Total_Precip_mm']) * 100\n",
    "# create percent field for Daily_Precip_Snow_mm by dividing by Full_Day_Total_Precip_mm\n",
    "sdfMonthly['Pct_of_Precip_as_Snow'] = (sdfMonthly['Daily_Precip_Snow_mm'] / sdfMonthly['Full_Day_Total_Precip_mm']) * 100\n",
    "\n",
    "\n",
    "# drop any rows with NaN or where Full_Day_Total_Precip_mm is greater than 0 and Daily_Precip_Rain_mm and Daily_Precip_Snow_mm are 0\n",
    "sdfMonthly = sdfMonthly.dropna(subset=['Full_Day_Total_Precip_mm'])\n",
    "sdfMonthly = sdfMonthly[(sdfMonthly['Full_Day_Total_Precip_mm'] > 0) & ((sdfMonthly['Daily_Precip_Rain_mm'] > 0) | (sdfMonthly['Daily_Precip_Snow_mm'] > 0))]\n",
    "\n",
    "# drop rows where month_year ends with 05, 06, 07, 08, 09\n",
    "sdfMonthly = sdfMonthly[~sdfMonthly.Month_Year.str.endswith(('05', '06', '07', '08', '09'))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "# create a plotly express stacked bar chart of Pct_of_Precip_as_Rain and Pct_of_Precip_as_Snow\n",
    "fig = px.bar(sdfMonthly, x='Month_Year', y=['Pct_of_Precip_as_Rain', 'Pct_of_Precip_as_Snow'], title='Monthly Precipitation Type')\n",
    "fig.update_layout(barmode='stack')\n",
    "\n",
    "# # add trendline of pct of precip as rain?\n",
    "\n",
    "# # add trace of line for total snow\n",
    "# fig.add_trace(go.Scatter(x=sdfMonthly['Month_Year'], y=sdfMonthly['Full_Day_Total_Precip_mm'], mode='lines', name='Total Precipitation (mm)'))\n",
    "\n",
    "# configure second y axis for total snow so that the right is 0 to 100 and the left is 0 to 1000\n",
    "\n",
    "# set y axis to be 0 to 100\n",
    "fig.update_yaxes(range=[0, 100], title_text='Percent of Precipitation')\n",
    "# add second y axis\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter chart as lines of total snow by month\n",
    "fig = px.line(sdfMonthly, x='Month_Year', y=['Full_Day_Total_Precip_mm', 'Daily_Precip_Rain_mm', 'Daily_Precip_Snow_mm'], title='Monthly Precipitation')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create a plotly express line chart\n",
    "fig = px.line(df, x=\"Month_Year\", y=\"Full_Day_Total_Precip_mm\", title='Total Full Day Precipitation')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total snowfall for each month and year\n",
    "monthly_snow = combined_data.groupby(['Month_Year']).agg({'Season_Total_Snow_cm': 'sum'}).reset_index()\n",
    "monthly_snow.Month_Year = monthly_snow.Month_Year.dt.strftime('%Y-%m')\n",
    "# create a plotly express line chart\n",
    "fig = px.line(monthly_snow, x=\"Month_Year\", y=\"Season_Total_Snow_cm\", title='Monthly Snowfall')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres of forest fuels reduction treated for wildfire in high-risk areas, map of prescribed fire treatment projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# EIP Service for Acres Treated\n",
    "eipForestTreatments = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/19\"\n",
    "\n",
    "# TRCD service ## Doesnt match EIP data ## from 2022 used in map though\n",
    "trcdLayer = \"https://services6.arcgis.com/1KtlSd2mklZMBKaz/ArcGIS/rest/services/Tahoe_Forest_Fuels_Tx_OFFICIAL_Public_View/FeatureServer/0\"\n",
    "\n",
    "# get the data\n",
    "dfTreatments = pd.read_json(eipForestTreatments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreatments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreatments.to_csv(\"EIP_ForestHealthTreatments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# EIP Service for Acres Treated\n",
    "eipForestTreatments = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/19\"\n",
    "\n",
    "# TRCD service ## Doesnt match EIP data ## from 2022 used in map though\n",
    "trcdLayer = \"https://services6.arcgis.com/1KtlSd2mklZMBKaz/ArcGIS/rest/services/Tahoe_Forest_Fuels_Tx_OFFICIAL_Public_View/FeatureServer/0\"\n",
    "\n",
    "# get the data\n",
    "dfTreatments = pd.read_json(eipForestTreatments)\n",
    "\n",
    "# display the data\n",
    "dfTreatments.head()\n",
    "# group treatments by year\n",
    "dfTreatments = dfTreatments.groupby(['IndicatorProjectYear']).sum().reset_index()\n",
    "dfTreatments.head()\n",
    "# create plotly figure of forest treatments by year\n",
    "fig = px.bar(dfTreatments, x='IndicatorProjectYear', y='IndicatorProjectValue', title='Forest Treatments by Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Acres Treated')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree species diversity and increasing old growth forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.features import FeatureLayer\n",
    "## historical species distribution and old growth data is not comparable to current data\n",
    "\n",
    "# display Old Growth Forest Acres\n",
    "oldGrowthLayer = \"https://maps.trpa.org/server/rest/services/Vegetation_Late_Seral/FeatureServer/0\"\n",
    "\n",
    "# get the feature layer as a spatially enabled dataframe\n",
    "# speciesData = FeatureLayer(speciesLayer).query().sdf\n",
    "oldGrowthData = FeatureLayer(oldGrowthLayer).query().sdf\n",
    "\n",
    "# summarize the data by Acres\n",
    "oldGrowthDataSummary = oldGrowthData.groupby('SeralStage').agg({'Acres': 'sum'}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVeg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# colors of the veg types\n",
    "colors = ['#d7d79e','#9ed7c2','#cdf57a','#b4d79e', \n",
    "          '#ff0000', '#a5f57a','#00a820','#df73ff', \n",
    "          '#3e72b0','#2f3f56', '#a8a800']\n",
    "\n",
    "# current species distribution Use \"TRPA_Veg_Type\" to display the current species distribution\n",
    "speciesLayer = \"https://maps.trpa.org/server/rest/services/Vegetation_Type/MapServer/0\"\n",
    "\n",
    "# get the feature layer as a spatially enabled dataframe\n",
    "dfVeg = FeatureLayer(speciesLayer).query().sdf\n",
    "\n",
    "# summarize the data by Acres\n",
    "dfVeg.TRPA_VegType.replace('', np.nan, inplace=True)\n",
    "dfVegType = dfVeg.groupby(\"TRPA_VegType\")[\"Acres\"].sum().reset_index()\n",
    "\n",
    "df = dfVegType.rename(columns={'TRPA_VegType':'Vegetation Type'})\n",
    "\n",
    "df['Vegetation Type'] = df['Vegetation Type'].replace(['Cushion Plant'],'Cushion Plant/Rocky Outcrop')\n",
    "\n",
    "fig = px.bar(df, y=\"Vegetation Type\", x=\"Acres\", color=\"Vegetation Type\", orientation=\"h\", hover_name=\"Vegetation Type\",\n",
    "             color_discrete_sequence=colors ,\n",
    "             title=\"Vegetation Abundance\"\n",
    "            )\n",
    "\n",
    "fig.update_traces(hovertemplate='<b>%{x:,.0f}</b> acres<extra></extra>')\n",
    "\n",
    "# set style variables\n",
    "template = 'plotly_white'\n",
    "font     = 'Calibri'\n",
    "\n",
    "fig.update_layout(font_family=font,\n",
    "                    template=template,\n",
    "                    showlegend=False,\n",
    "                    hovermode=\"y unified\",\n",
    "                    yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of fire by low, moderate, & high severity by management zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial analysis for fire severity\n",
    "import arcpy\n",
    "\n",
    "# reclass Low Severity flame length raster\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\"):\n",
    "    out_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=r\"F:\\\\GIS\\\\PROJECTS\\\\ForestHealth_Intiative\\\\ThresholdUpdate\\\\Data\\\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbLowSeverity_2022_ACCEL_30m_Tahoe\",\n",
    "        reclass_field=\"Value\",\n",
    "        remap=\"0 0.600000 0;0.600000 1 1\",\n",
    "        missing_values=\"DATA\"\n",
    "    )\n",
    "    out_raster.save(r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_Reclass_Low_60thPercentile\")\n",
    "\n",
    "# convert reclassified raster to polygon\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=r\"Fire Severity\\Low Severity Fire\",\n",
    "    out_polygon_features=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbableLowSeverityFire\",\n",
    "    simplify=\"NO_SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")\n",
    "\n",
    "# identity analysis\n",
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"Boundaries\\Forest Management Zone\",\n",
    "    identity_features=\"FunctionalFire_ProbableLowSeverityFire\",\n",
    "    out_feature_class=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")\n",
    "\n",
    "# Calculate the area in acres for each feature\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=r\"Fire Severity\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# export table to database\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=r\"Fire Severity\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_ProbabilityLowSeverityFire_by_ForestManagmentZone\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    sort_field=None\n",
    ")\n",
    "\n",
    "# reclass High Severity flame length raster\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\"):\n",
    "    out_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=r\"F:\\\\GIS\\\\PROJECTS\\\\ForestHealth_Intiative\\\\ThresholdUpdate\\\\Data\\\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbHighSeverity_2022_ACCEL_30m_Tahoe\",\n",
    "        reclass_field=\"Value\",\n",
    "        remap=\"0 0.600000 0;0.600000 1 1\",\n",
    "        missing_values=\"DATA\"\n",
    "    )\n",
    "    out_raster.save(r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_Reclass_High_60thPercentile\")\n",
    "\n",
    "# convert reclassified raster to polygon\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=r\"Fire Severity\\High Severity Fire\",\n",
    "    out_polygon_features=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbableHighSeverityFire\",\n",
    "    simplify=\"NO_SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")\n",
    "\n",
    "# identity analysis\n",
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"Boundaries\\Forest Management Zone\",\n",
    "    identity_features=\"FunctionalFire_ProbableHighSeverityFire\",\n",
    "    out_feature_class=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")\n",
    "\n",
    "# Calculate the area in acres for each feature\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=r\"Fire Severity\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# export table to database\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=r\"Fire Severity\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_ProbabilityHighSeverityFire_by_ForestManagmentZone\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    sort_field=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "highseverityURL = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/129\"\n",
    "lowseverityURL  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/130\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(highseverityURL)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_highseverity = feature_layer.query().sdf\n",
    "\n",
    "sdf_highseverity.head()\n",
    "# summarize the area of high and low severity fire by name and gridcode\n",
    "highseverity_summary = sdf_highseverity.groupby(['Name', 'gridcode'])['Acres'].sum().reset_index()\n",
    "\n",
    "# reclassify values of gridcode in new field called 'Severity' with 1 = \">60% chance of high severity fire\" and 0 = \"<60% chance of high severity fire\"\n",
    "highseverity_summary['Severity'] = np.where(highseverity_summary['gridcode'] == 1, \">60% chance of high severity fire\", \"<60% chance of high severity fire\")\n",
    "\n",
    "# Plot using Plotly Express to create a stacked bar chart of Severity by Name with the bar chart being 100% stacked\n",
    "fig = px.histogram(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barnorm='percent',barmode='stack')\n",
    "# fig = px.bar(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barmode='stack')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowseverityURL  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/130\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(lowseverityURL)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_lowseverity = feature_layer.query().sdf\n",
    "\n",
    "sdf_lowseverity.head()\n",
    "# summarize the area of high and low severity fire by name and gridcode\n",
    "lowseverity_summary = sdf_lowseverity.groupby(['Name', 'gridcode'])['Acres'].sum().reset_index()\n",
    "\n",
    "# reclassify values of gridcode in new field called 'Severity' \n",
    "lowseverity_summary['Severity'] = np.where(lowseverity_summary['gridcode'] == 1, \">60% chance of low severity fire\", \"<60% chance of low severity fire\")\n",
    "\n",
    "# Plot using Plotly Express to create a stacked bar chart of Severity by Name with the bar chart being 100% stacked\n",
    "fig = px.histogram(lowseverity_summary, x='Name', y='Acres', color='Severity', title='Low Severity Fire by Forest Management Zone', barnorm='percent',barmode='stack')\n",
    "# fig = px.bar(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Moderate Severity Fire does not exist in the service....USFS data is needed to complete the analysis, but they didnt provide it in the data package\n",
    "\n",
    "# we could get at this by doing the math's between low and high severity fire, but that would be a bit of a stretch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres treated for aquatic invasive species. *We could gain additional clarity regarding this indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# EIP Service for Acres Treated\n",
    "eipInvasive = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/15\"\n",
    "\n",
    "df = pd.read_json(eipInvasive)\n",
    "\n",
    "sum_df = df.groupby('IndicatorProjectYear')['IndicatorProjectValue'].cumsum()\n",
    "\n",
    "display(sum_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres of restored high-quality wetlands and meadows helping to store flood waters. *We are expecting additional clarity regarding this indicator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# EIP Service for SEZ Restored or Enhanced\n",
    "eipSEZRestored = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/9\"\n",
    "\n",
    "# GIS of SEZ Enchanced\n",
    "trpaSEZEnhancedRestored = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/126\"\n",
    "# GIS of SEZ Restored\n",
    "trpaSEZRestored = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/127\"\n",
    "# get the data\n",
    "df = pd.read_json(eipSEZRestored)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased number of parcels with Stormwater Best Management Practices (BMPs) improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BMP data as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# # EIP Service for BMPs installed\n",
    "# bmpsInstalled = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/4\"\n",
    "\n",
    "# BMP map service from BMP database\n",
    "bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "\n",
    "# get the data\n",
    "feature_layer = FeatureLayer(bmpsLayer)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bmps = feature_layer.query().sdf\n",
    "\n",
    "# total BMPs installed\n",
    "total_bmps = sdf_bmps['OBJECTID'].count()\n",
    "\n",
    "# filter total BMPs CertificateIssued = 1\n",
    "sdf_bmps_cert = sdf_bmps[sdf_bmps['CertificateIssued'] == 1]\n",
    "\n",
    "# total BMPs installed\n",
    "total_bmps_cert = sdf_bmps_cert['OBJECTID'].count()\n",
    "\n",
    "# create Year column\n",
    "sdf_bmps_cert['Year'] = pd.DatetimeIndex(sdf_bmps_cert['CertDate']).year\n",
    "\n",
    "# total BMPs installed per year\n",
    "total_bmps_cert_year = sdf_bmps_cert.groupby('Year')['OBJECTID'].count().reset_index()\n",
    "\n",
    "# create plotly figure of BMPs installed per year\n",
    "fig = px.bar(total_bmps_cert_year, x='Year', y='OBJECTID', title='BMPs Installed per Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='BMPs Installed')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulutive sum of BMPs installed per year\n",
    "total_bmps_cert_year['Cumulative BMPs Installed'] = total_bmps_cert_year['OBJECTID'].cumsum()\n",
    "# create plotly figure of BMPs installed per year\n",
    "fig = px.bar(total_bmps_cert_year, x='Year', y='Cumulative BMPs Installed', title='BMPs Installed')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Cumulative BMPs Installed')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMP map service from BMP database\n",
    "bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "# get the data\n",
    "feature_layer = FeatureLayer(bmpsLayer)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bmps = feature_layer.query().sdf\n",
    "\n",
    "# filter total BMPs CertificateIssued = 1\n",
    "sdf_bmps_cert = sdf_bmps[sdf_bmps['CertificateIssued'] == 1]\n",
    "\n",
    "# total developed parcels, use .loc to get EXISTING_LANDUSE does not equal \"Vacant\" or \"Open Space\"\n",
    "parcelsDeveloped = sdf_bmps.loc[~sdf_bmps['EXISTING_LANDUSE'].isin(['Vacant', 'Open Space'])]\n",
    "parcelsDeveloped = parcelsDeveloped['OBJECTID'].count()\n",
    "\n",
    "# total bmps certified by year compared to total developed parcels\n",
    "# create Year column\n",
    "sdf_bmps_cert['Year'] = pd.DatetimeIndex(sdf_bmps_cert['CertDate']).year\n",
    "bmpsCertByYear = sdf_bmps_cert.groupby('Year')['OBJECTID'].count().reset_index()\n",
    "bmpsCertByYear['Cumulative BMPs Installed'] = bmpsCertByYear['OBJECTID'].cumsum()\n",
    "bmpsCertByYear['Developed Parcels'] = parcelsDeveloped\n",
    "bmpsCertByYear['BMPs per Developed Parcel'] = bmpsCertByYear['Cumulative BMPs Installed'] / bmpsCertByYear['Developed Parcels']\n",
    "bmpsCertByYear['BMPs per Developed Parcel'] = bmpsCertByYear['BMPs per Developed Parcel'].round(2)\n",
    "\n",
    "# create plotly figure of BMPs installed per year\n",
    "fig = px.bar(bmpsCertByYear, x='Year', y='BMPs per Developed Parcel', title='BMPs Installed per Developed Parcel')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='% BMPs Installed per Developed Parcel')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data_bmp():\n",
    "    # BMP map service from BMP database\n",
    "    bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "\n",
    "    # get data from map service\n",
    "    data = get_fs_data(bmpsLayer)\n",
    "\n",
    "    # select rows where BMPs CertificateIssued = 1 using .loc\n",
    "    data.loc[data['CertificateIssued'] == 1]\n",
    "\n",
    "    # create Year column\n",
    "    data['Year'] = pd.DatetimeIndex(data['CertDate']).year\n",
    "\n",
    "    # total bmps certified by year\n",
    "    bmpsCertByYear = data.groupby('Year')['OBJECTID'].count().reset_index()\n",
    "\n",
    "    # total developed parcels, get EXISTING_LANDUSE does not equal \"Vacant\" or \"Open Space\"\n",
    "    parcelsDeveloped = data.loc[~data['EXISTING_LANDUSE'].isin(['Vacant', 'Open Space'])]\n",
    "\n",
    "    # total developed parcels\n",
    "    bmpsCertByYear['Developed Parcels'] = parcelsDeveloped['OBJECTID'].count()\n",
    "\n",
    "    # cumulative sum of BMPs installed per year\n",
    "    bmpsCertByYear['Cumulative BMPs Installed'] = bmpsCertByYear['OBJECTID'].cumsum()\n",
    "\n",
    "    # BMPs installed per year compared to total developed parcels per year\n",
    "    bmpsCertByYear['BMPs per Developed Parcel'] = bmpsCertByYear['Cumulative BMPs Installed'] / bmpsCertByYear['Developed Parcels'].round(2)\n",
    "\n",
    "    # BMPs installed per year compared to total developed parcels per year but subtracting the BMPs installed from the total developed parcels\n",
    "    bmpsCertByYear['Developed Parcels Without a BMP'] = bmpsCertByYear['Developed Parcels'] - bmpsCertByYear['Cumulative BMPs Installed']\n",
    "    \n",
    "    # drop objectid\n",
    "    df = bmpsCertByYear.drop(columns=['OBJECTID'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_bmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_bmp():\n",
    "    # BMP map service from BMP database\n",
    "    bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "    # get data from map service\n",
    "    data = get_fs_data(bmpsLayer)\n",
    "    # select rows where BMPs CertificateIssued = 1 (True)\n",
    "    data.loc[data['CertificateIssued'] == 1]\n",
    "    # create Year column\n",
    "    data['Year'] = pd.DatetimeIndex(data['CertDate']).year\n",
    "    # total bmps certified by year\n",
    "    bmpsCertByYear = data.groupby('Year')['OBJECTID'].count().reset_index()\n",
    "    # total developed parcel rows\n",
    "    parcelsDeveloped = data.loc[~data['EXISTING_LANDUSE'].isin(['Vacant', 'Open Space'])]\n",
    "    # set total developed parcels field\n",
    "    bmpsCertByYear['Developed Parcels'] = parcelsDeveloped['OBJECTID'].count()\n",
    "    # cumulative sum of BMPs installed per year\n",
    "    bmpsCertByYear['Total BMPs Installed'] = bmpsCertByYear['OBJECTID'].cumsum()\n",
    "    # BMPs installed per year compared to total developed parcels per year\n",
    "    bmpsCertByYear['BMPs per Developed Parcel'] = (bmpsCertByYear['Total BMPs Installed'] / bmpsCertByYear['Developed Parcels']).round(2)\n",
    "    # BMPs installed per year compared to total developed parcels per year but subtracting the BMPs installed from the total developed parcels\n",
    "    bmpsCertByYear['Developed Parcels Without a BMP'] = bmpsCertByYear['Developed Parcels'] - bmpsCertByYear['Total BMPs Installed']\n",
    "    # drop objectid\n",
    "    df = bmpsCertByYear.drop(columns=['OBJECTID'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMP map service from BMP database\n",
    "bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "\n",
    "# get data from map service\n",
    "data = get_fs_data(bmpsLayer)\n",
    "# select rows where BMPs CertificateIssued = 1 (True)\n",
    "df = data.loc[data['CertificateIssued'] == 1]\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create staked bar chart of BMPs installed per year compared to total developed parcels per year but subtracting the BMPs installed from the total developed parcels\n",
    "bmpsCertByYear['Developed Parcels Without a BMP'] = bmpsCertByYear['Developed Parcels'] - bmpsCertByYear['Cumulative BMPs Installed']\n",
    "\n",
    "bmpsCertByYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create staked bar chart of BMPs installed per year compared to total developed parcels per year but subtracting the BMPs installed from the total developed parcels\n",
    "fig = px.bar(bmpsCertByYear, x='Year', y=['Cumulative BMPs Installed', 'Developed Parcels Without a BMP'], title='BMPs Installed per Developed Parcel')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='BMPs Installed per Developed Parcel')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase in square feet of urban development treated by areawide stormwater infrastructure within key watersheds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reqeusted \"Year of Completion\" data for each area wide storm water treatment from Shay. TBD if this is available\n",
    "\n",
    "# area wide storm water treamtent layer # we can't do this analysis without the year of completion data\n",
    "areawideLayer  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/120\"\n",
    "\n",
    "# developed area layers\n",
    "impervious2010Layer   = \"https://maps.trpa.org/server/rest/services/Impervious_Surface_2010/MapServer\"\n",
    "impervious2019Layer   = \"https://maps.trpa.org/server/rest/services/Impervious_Surface_2019/MapServer\"\n",
    "imperviousChangeLayer = \"https://maps.trpa.org/server/rest/services/Impervious_Surface_Change_2010_to_2019/MapServer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.Impervious\\SDE.Impervious_2019\",\n",
    "    identity_features=r\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.EIP\\SDE.Existing_Drainage_Areas\",\n",
    "    out_feature_class=r\"C:\\GIS\\Scratch.gdb\\Impervious_2019_Identity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=\"Impervious_2019_Identity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=\"Impervious_2019_Identity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_Impervious_Identify_Areawide_ByYear\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    field_mapping='FID_Impervious_2019 \"FID_Impervious_2019\" true true false 4 Long 0 0,First,#,Impervious_2019_Identity,FID_Impervious_2019,-1,-1;Feature \"Feature\" true true false 8 Text 0 0,First,#,Impervious_2019_Identity,Feature,0,7;Surface \"Surface\" true true false 4 Text 0 0,First,#,Impervious_2019_Identity,Surface,0,3;FID_Existing_Drainage_Areas \"FID_Existing_Drainage_Areas\" true true false 4 Long 0 0,First,#,Impervious_2019_Identity,FID_Existing_Drainage_Areas,-1,-1;Drainage_Area_Name \"Name\" true true false 100 Text 0 0,First,#,Impervious_2019_Identity,Drainage_Area_Name,0,99;Status \"Status\" true true false 50 Text 0 0,First,#,Impervious_2019_Identity,Status,0,49;Year_Completed \"Year_Completed\" true true false 4 Text 0 0,First,#,Impervious_2019_Identity,Year_Completed,0,3;Acres \"Acres\" true true false 8 Double 0 0,First,#,Impervious_2019_Identity,Acres,-1,-1',\n",
    "    sort_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# REST service for impervious area wide\n",
    "imperviousAreaWide = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/140\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(imperviousAreaWide)\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_impervious = feature_layer.query().sdf\n",
    "\n",
    "# summarize total area of Surface = Hard Surface\n",
    "sdf_impervious_hard = sdf_impervious[sdf_impervious['Surface'] == 'Hard']\n",
    "\n",
    "# summarize the area of hard surface covered by status = completed or active\n",
    "sdf_impervious_hard_summary = sdf_impervious_hard.groupby(['Status', 'Year_Completed'])['Acres'].sum().reset_index()\n",
    "\n",
    "# filter out Status is not ''\n",
    "sdf_impervious_hard_summary = sdf_impervious_hard_summary[sdf_impervious_hard_summary['Status'] != '']\n",
    "# group status active and constructed to completed\n",
    "sdf_impervious_hard_summary['Status'] = sdf_impervious_hard_summary['Status'].replace(['Active', 'Constructed'], 'Completed')\n",
    "\n",
    "# add acres in cumulative sum\n",
    "sdf_impervious_hard_summary['Cumulative Acres'] = sdf_impervious_hard_summary.groupby('Status')['Acres'].cumsum()\n",
    "\n",
    "total_acres = sdf_impervious_hard['Acres'].sum()\n",
    "\n",
    "# create cumulative sum of acres of status - completed\n",
    "sdf_impervious_hard_summary['Cumulative Acres'] = sdf_impervious_hard_summary['Acres'].cumsum()\n",
    "\n",
    "# subtract area covereed by cumulatve sum from total acres\n",
    "sdf_impervious_hard_summary['Acres Remaining'] = total_acres - sdf_impervious_hard_summary['Cumulative Acres']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_impervious_hard_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# areawide overlay URL\n",
    "areawideOverlay = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/140\"\n",
    "# get data from map service\n",
    "data = get_fs_data(areawideOverlay)\n",
    "# summarize total area of Surface = Hard Surface\n",
    "df = data.loc[data['Surface'] == 'Hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Surface.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets data from the TRPA server\n",
    "def get_fs_data(service_url):\n",
    "    feature_layer = FeatureLayer(service_url)\n",
    "    query_result = feature_layer.query()\n",
    "    # Convert the query result to a list of dictionaries\n",
    "    feature_list = query_result.features\n",
    "    # Create a pandas DataFrame from the list of dictionaries\n",
    "    all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "    # return data frame\n",
    "    return all_data\n",
    "\n",
    "def get_areawide_data():\n",
    "    # areawide overlay URL\n",
    "    areawideOverlay = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/140\"\n",
    "    # get data from map service\n",
    "    data = get_fs_data(areawideOverlay)\n",
    "    # summarize total area of Surface = Hard Surface\n",
    "    df = data.loc[data['Surface'] == 'Hard']\n",
    "    # calculate total acres\n",
    "    total_acres = df['Acres'].sum()\n",
    "    # summarize the area of hard surface covered by status = completed or active\n",
    "    sdf_impervious_hard_summary = df.groupby(['Status', 'Year_Completed'])['Acres'].sum().reset_index()\n",
    "    # filter out Status is not ''\n",
    "    sdf_impervious_hard_summary = sdf_impervious_hard_summary[sdf_impervious_hard_summary['Status'] != '']\n",
    "    # group status active and constructed to completed\n",
    "    sdf_impervious_hard_summary['Status'] = sdf_impervious_hard_summary['Status'].replace(['Active', 'Constructed'], 'Completed')\n",
    "    # add acres in cumulative sum\n",
    "    sdf_impervious_hard_summary['Cumulative Acres'] = sdf_impervious_hard_summary.groupby('Status')['Acres'].cumsum()\n",
    "    # create cumulative sum of acres of status - completed\n",
    "    sdf_impervious_hard_summary['Cumulative Acres'] = sdf_impervious_hard_summary['Acres'].cumsum()\n",
    "    # subtract area covereed by cumulatve sum from total acres\n",
    "    sdf_impervious_hard_summary['Acres Remaining'] = total_acres - sdf_impervious_hard_summary['Cumulative Acres']\n",
    "    df = sdf_impervious_hard_summary\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_areawide_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areawide overlay URL\n",
    "areawideOverlay = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/140\"\n",
    "# get data from map service\n",
    "data = get_fs_data(areawideOverlay)\n",
    "# summarize total area of Surface = Hard Surface\n",
    "df = data.loc[data['Surface'] == 'Hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total acres\n",
    "total_acres = df['Acres'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_areawide_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ploty figure of impervious area wide by year\n",
    "fig = px.bar(sdf_impervious_hard_summary, x='Year_Completed', y='Cumulative Acres', color='Status', title='Impervious Area Wide by Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Acres of Hard Surface Covered by Yera')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploty figure of impervious area wide by year\n",
    "fig = px.bar(sdf_impervious_hard_summary, x='Year_Completed', y=['Cumulative Acres', 'Acres Remaining'], title='Impervious Area Wide by Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Acres of Hard Surface Covered by Yera')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of housing units in town centers and share of affordable housing in Town Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# town center layer\n",
    "towncenterLayer = \"https://maps.trpa.org/server/rest/services/LocalPlan/MapServer/2\"\n",
    "# parcel development history layer for 2012, and 2018-2022 # 2021 and 2023 coming soon. other years are unknown\n",
    "parcelDevelopmentHistoryLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/17\"\n",
    "# deed restricted housing layer\n",
    "deedRestrictedHousingLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/20\"\n",
    "\n",
    "# get data from map service as a spatially enabled dataframe\n",
    "towncenterData = FeatureLayer(towncenterLayer).query().sdf\n",
    "parcelDevelopmentHistoryData = FeatureLayer(parcelDevelopmentHistoryLayer).query().sdf\n",
    "deedRestrictedHousingData = FeatureLayer(deedRestrictedHousingLayer).query().sdf\n",
    "\n",
    "# query parcel development history layer for 2022\n",
    "parcelDevelopmentHistory2022 = parcelDevelopmentHistoryData[parcelDevelopmentHistoryData['Year'] == 2022]\n",
    "\n",
    "# query deed restricted housing layer for affordable housing\n",
    "deedRestrictedAffordableHousing = deedRestrictedHousingData[deedRestrictedHousingData['Type'] == 'Affordable']\n",
    "\n",
    "# merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature layer as a spatially enabled dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in share of homes with electric or solar energy fuel compared to oil/gas over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kathleen did this. need to get the data in our database and web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of deed-restricted affordable, moderate, and achievable units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# deed restriction service\n",
    "deedRestrictionService = \"https://www.laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\"\n",
    "\n",
    "# read in deed restricted parcels\n",
    "dfDeed = pd.read_json(deedRestrictionService)\n",
    "\n",
    "# filter out deed restrictions that are not affordable housing\n",
    "dfDeed = dfDeed.loc[dfDeed['DeedRestrictionType'].isin(['Affordable Housing', 'Achievable Housing', 'Moderate Income Housing'])]\n",
    "\n",
    "# create year column\n",
    "dfDeed['Year'] = dfDeed['RecordingDate'].str[-4:]\n",
    "\n",
    "# group by type and year\n",
    "df = dfDeed.groupby(['DeedRestrictionType', 'Year']).size().reset_index(name='Total')\n",
    "\n",
    "# sort by year\n",
    "df.sort_values('Year', inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df = df.rename(columns={'DeedRestrictionType': 'Type', 'Year': 'Year', 'Total': 'Count'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Type': np.repeat(df['Type'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Type'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Type', 'Year'], how='left')\n",
    "\n",
    "# Replace NaN values in 'Count' with 0\n",
    "df['Count'] = df['Count'].fillna(0)\n",
    "\n",
    "# Ensure 'Count' is of integer type\n",
    "df['Count'] = df['Count'].astype(int)\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Count'] = df.sort_values('Year').groupby('Type')['Count'].cumsum()\n",
    "\n",
    "# create cumuluative total of deed restricted parcels by type\n",
    "fig = px.line(df, x=\"Year\", y=\"Cumulative Count\", color=\"Type\", title=\"Deed Restricted Parcels\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of renewable energy as a share of total energy used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kathleen did this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total transit ridership by transit systems\n",
    "* https://www.laketahoeinfo.org/Indicator/Detail/46/Overview\n",
    "* this doesn't work yet. Talking to ESA to get web service stood up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# Data not avaialble from LTinfo yet. Shannon is working on a service for this. I will get the data from Kira as a placeholder for now.\n",
    "# indicator data saved from Kira's email\n",
    "eipTransit = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/131\"\n",
    "\n",
    "# read in spatial enabled dataframe\n",
    "dfTransit = FeatureLayer(eipTransit).query().sdf\n",
    "\n",
    "# drop ObjectID\n",
    "dfTransit = dfTransit.drop(columns=['OBJECTID'])\n",
    "# stack data by month\n",
    "dfTransit = dfTransit.melt(id_vars=['MONTH'], var_name='Name', value_name='Ridership')\n",
    "\n",
    "# create Year field from last two characters of month but add 20 prefix\n",
    "dfTransit['Year'] = '20' + dfTransit['MONTH'].str[-2:]\n",
    "# strip the last three characters from month\n",
    "dfTransit['Month'] = dfTransit['MONTH'].str[:-3]\n",
    "# drop MONTH\n",
    "dfTransit = dfTransit.drop(columns=['MONTH'])\n",
    "# make the values in Month the real names of the months\n",
    "dfTransit['Month'] = dfTransit['Month'].replace(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], \n",
    "                                                ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
    "\n",
    "\n",
    "# create a Date type field of Month and Year\n",
    "dfTransit['Date'] = dfTransit['Month'] + ' ' + dfTransit['Year']\n",
    "# convert Date to datetime\n",
    "dfTransit['Date'] = pd.to_datetime(dfTransit['Date'], format='%B %Y')\n",
    "dfTransit = dfTransit.sort_values('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plotly figure of transit ridership by date \n",
    "fig = px.line(dfTransit, x=\"Date\", y=\"Ridership\", color=\"Name\", title=\"Transit Ridership\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily per capita Vehicles Miles Traveled (VMT) and progress towards VMT target. The RTP (2021) identifies a Daily per capita VMT target set at a 6.8 percent reduction from 2018 levels by 2045 (2018 per capita daily VMT is 12.48, goal is 11.63)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh coming 2/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage of electric bus routes and alternative fuel, such as EV charging for vehicles and bicycles\n",
    "* Primary source: https://www.plugshare.com/ requested access to their API\n",
    "* Secondary (if needed to cross-check): https://afdc.energy.gov/stations/#/find/nearest\n",
    "\n",
    "* current in-house data: https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no real info on this right now. Will checking with Kira on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline mode share and weekday or seasonal variation. The Tahoe RTP (2021) includes the following Non-Auto Mode Share Target: Improve average non-auto mode share calculated from the two most recent TRPA travel survey results; the current performance on target at 24.5% (2018-20 average) up from 18% in 2014-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh coming 2/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transportation access in priority communities. The Tahoe RTP (2021) includes a target to increase access to each mode for Priority communities to 100% by 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will check in with Kira on this again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased lane miles of low-stress bicycle facilities (both bicycle and pedestrian facilities that are considered comfortable enough for all users and abilities, and implicitly measures active transportation network connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Count'] = df.sort_values('Year').groupby(['Year', 'Class'])['Miles'].cumsum()\n",
    "\n",
    "# get rid of all columns except for Year, Class, and Cumulative Count\n",
    "df = df[['Year', 'Class', 'Cumulative Count']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of all columns except for Year, Class, and Cumulative Count\n",
    "df = df[['Year', 'Class', 'Cumulative Miles']]\n",
    "# get all rows where Year = 2006\n",
    "df_2006 = df[df['Year'] == 2006]\n",
    "# display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "\n",
    "# bring in 2005 data  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "\n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# \n",
    "df =df.groupby(['Year', 'Class'])['Miles'].sum().reset_index()\n",
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "\n",
    "# bring in 2005 data  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "\n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# create grouped dataframe\n",
    "df = df.groupby(['Year', 'Class'])['Miles'].sum().reset_index()\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Miles'] = df.sort_values('Year').groupby('Class')['Miles'].cumsum()\n",
    "\n",
    "# create cumuluative total of miles of bike lanes by Class\n",
    "fig = px.line(df, x=\"Year\", y=\"Cumulative Miles\", color=\"Class\", title=\"Miles of Bike Lane by Type\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Household Income (MHI) by community area (to be determined) and disaggregated by remote and non-remote workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census table\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing costs (median home sales price and rental rates, by jurisdiction); include cost per unit and cost per square foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sean is getting COSTAR and Property Radar data for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing tenure (rented full-time, owner-occupied, second home), disaggregated by race, ethnicity, and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of workers who commute into the basin, origin demographics, distance travelled, difference in travel time by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transient Occupancy Tax revenue and changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh coming 2/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent employment and median wages by sector and overall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to recreation sites, fresh food, and healthcare for zero-vehicle households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wiht Kira on this. Will make a map of what we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firewise communities in the Tahoe basin, coolling centers/heating centers, resources, and emergency infrastructure (medical centers with supplies, fire response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population disaggregated by race and ethnicity, age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number/share of households with access and functional needs (These can be referred to as vulnerable populations including populations such as persons with disabilities, older adults, children, limited English proficiency, and transportation disadvantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trpa-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
