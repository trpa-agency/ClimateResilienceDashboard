{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Tahoe region greenhouse gas (GHG) emissions and support the measurement of carbon sequestration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHG Data\n",
    "ghgTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/124\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track poor air quality, wildfire smoke, and extreme heat trends regionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting Purple Air data\n",
    "\n",
    "# TRPA Air Quality Monitoring data\n",
    "trpaAirqualityStationLayer = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/16\"\n",
    "trpaairqualityDailyTable   = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/17\"\n",
    "trpaairqualityYearlyTable  = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/46\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Purple Air data\n",
    "purpleAirSensorLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/143\"\n",
    "\n",
    "# get data as spatially enabled dataframe from feature layer\n",
    "fl = FeatureLayer(purpleAirSensorLayer)\n",
    "sdfPurpleAir = fl.query().sdf\n",
    "\n",
    "# groupby date and get the mean of pm25\n",
    "sdfPurpleAir = sdfPurpleAir.groupby('date')['mean_pm25'].mean().reset_index()\n",
    "# creat a plotly express line chart\n",
    "fig = px.line(sdfPurpleAir, x=\"date\", y=\"mean_pm25\", title='Purple Air PM2.5')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color background of plotly by x axis value and gradient fill\n",
    "fig = px.line(sdfPurpleAir, x=\"date\", y=\"mean_pm25\", title='Purple Air PM2.5', line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.update_traces(line_color='blue')\n",
    "fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake Tahoe water level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# tahoe city site number\n",
    "site_number = '10337000'\n",
    "\n",
    "# USGS API URL\n",
    "url = f'https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065&startDT=2021-01-01&endDT=2021-01-30'\n",
    "\n",
    "# function to get data from USGS API as dataframe\n",
    "def get_usgs_data(days):\n",
    "    site_number = 10337000\n",
    "    \n",
    "    # Calculate the start and end dates based on the selected time range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    url = f'https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065&startDT={start_date_str}&endDT={end_date_str}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    time_series_data = data['value']['timeSeries'][0]['values'][0]['value']\n",
    "\n",
    "    df = pd.DataFrame(time_series_data)\n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "    df['value'] = df['value'] + 6220\n",
    "    return df\n",
    "\n",
    "# create plot of lake level\n",
    "def update_chart(selected_days):\n",
    "    df = get_usgs_data(selected_days)\n",
    "\n",
    "    fig = px.line(df, x='dateTime', y='value', title='Lake Tahoe Water Level')\n",
    "    fig.update_xaxes(title_text='Time')\n",
    "    fig.update_yaxes(title_text='Water Level (ft)')\n",
    "\n",
    "    return fig\n",
    "\n",
    "# create plot of lake level\n",
    "update_chart(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The USGS Site at Tahoe City only has data for the last 5968 days (~16.3 years) October 2007\n",
    "days = 5968  \n",
    "df = get_usgs_data(days)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual average water temperature, including surface water temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# get data from TERC service\n",
    "lakeTempURL = \"https://tepfsail50.execute-api.us-west-2.amazonaws.com/v1/report/ns-station-range?rptdate=20240130&rptend=20240202&id=4\"\n",
    "# get data from TERC\n",
    "response = requests.get(lakeTempURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake clarity measured by Secchi Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secchi depth data\n",
    "secchiDepth    = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/14\"\n",
    "secchiDepthAll = \"https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/13\"\n",
    "secchiDepth    = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/125\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total precipitation in water per year, extreme precipitation, and snow as a fraction of annual precipitation\n",
    "* https://www.ncei.noaa.gov/cdo-web/\n",
    "* https://www.weather.gov/documentation/services-web-api\n",
    "* https://www.ncdc.noaa.gov/cdo-web/api/v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# mbindl@trpa.gov API key\n",
    "api_key = 'LaQrgmyzkUTfbBeUDaUjYiQLLOCXkhYY'\n",
    "\n",
    "# Define the base URL for the NOAA API\n",
    "base_url = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/'\n",
    "\n",
    "# Define the endpoint you want to access (e.g., 'stations')\n",
    "endpoint = 'stations'\n",
    "\n",
    "# Define the parameters for your request (e.g., dataset, location)\n",
    "params = {\n",
    "    'datasetid': 'GHCND',  # Global Historical Climatology Network - Daily (GHCND)\n",
    "    'locationid': 'FIPS:06',  # FIPS code for California\n",
    "    'limit': 1000  # Maximum number of results to return\n",
    "}\n",
    "\n",
    "# Make the request to the NOAA API\n",
    "response = requests.get(base_url + endpoint, headers={'token': api_key}, params=params)\n",
    "\n",
    "# Parse the JSON response\n",
    "data = response.json()\n",
    "\n",
    "# The 'results' field of the response contains the list of stations\n",
    "stations = data['results']\n",
    "\n",
    "# convert the list of stations to a DataFrame\n",
    "stations_df = pd.DataFrame(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NOAA data obersavitoins for the last 30 years\n",
    "# Define the endpoint you want to access (e.g., 'stations')\n",
    "endpoint = 'data'\n",
    "# Define the parameters for your request (e.g., dataset, location)\n",
    "params = {\n",
    "    'datasetid': 'GHCND',  # Global Historical Climatology Network - Daily (GHCND)\n",
    "    'locationid': 'FIPS:06',  # FIPS code for California\n",
    "    'stationid': 'GHCND:USW00023234',  # Station ID for Tahoe City\n",
    "    'startdate': '1991-01-01',\n",
    "    'enddate': '2021-01-01',\n",
    "    'limit': 1000  # Maximum number of results to return\n",
    "}\n",
    "# Make the request to the NOAA API\n",
    "response = requests.get(base_url + endpoint, headers={'token': api_key}, params=params)\n",
    "# Parse the JSON response\n",
    "data = response.json()\n",
    "# The 'results' field of the response contains the list of stations\n",
    "observations = data['results']\n",
    "# convert the list of stations to a DataFrame\n",
    "observations_df = pd.DataFrame(observations)\n",
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from NOAA API\n",
    "# NOAA API URL for Tahoe area\n",
    "noaaURL = \"https://api.weather.gov/gridpoints/MTR/155,80/forecast\"\n",
    "response = requests.get(noaaURL)\n",
    "data = response.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres of forest fuels reduction treated for wildfire in high-risk areas, map of prescribed fire treatment projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# EIP Service for Acres Treated\n",
    "eipForestTreatments = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/19\"\n",
    "\n",
    "# TRCD service ## Doesnt match EIP data ## from 2022 used in map though\n",
    "trcdLayer = \"https://services6.arcgis.com/1KtlSd2mklZMBKaz/ArcGIS/rest/services/Tahoe_Forest_Fuels_Tx_OFFICIAL_Public_View/FeatureServer/0\"\n",
    "\n",
    "# get the data\n",
    "dfTreatments = pd.read_json(eipForestTreatments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreatments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreatments.to_csv(\"EIP_ForestHealthTreatments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# EIP Service for Acres Treated\n",
    "eipForestTreatments = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/19\"\n",
    "\n",
    "# TRCD service ## Doesnt match EIP data ## from 2022 used in map though\n",
    "trcdLayer = \"https://services6.arcgis.com/1KtlSd2mklZMBKaz/ArcGIS/rest/services/Tahoe_Forest_Fuels_Tx_OFFICIAL_Public_View/FeatureServer/0\"\n",
    "\n",
    "# get the data\n",
    "dfTreatments = pd.read_json(eipForestTreatments)\n",
    "\n",
    "# display the data\n",
    "dfTreatments.head()\n",
    "# group treatments by year\n",
    "dfTreatments = dfTreatments.groupby(['IndicatorProjectYear']).sum().reset_index()\n",
    "dfTreatments.head()\n",
    "# create plotly figure of forest treatments by year\n",
    "fig = px.bar(dfTreatments, x='IndicatorProjectYear', y='IndicatorProjectValue', title='Forest Treatments by Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Acres Treated')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree species diversity and increasing old growth forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.features import FeatureLayer\n",
    "## historical species distribution and old growth data is not comparable to current data\n",
    "\n",
    "# display Old Growth Forest Acres\n",
    "oldGrowthLayer = \"https://maps.trpa.org/server/rest/services/Vegetation_Late_Seral/FeatureServer/0\"\n",
    "\n",
    "# get the feature layer as a spatially enabled dataframe\n",
    "# speciesData = FeatureLayer(speciesLayer).query().sdf\n",
    "oldGrowthData = FeatureLayer(oldGrowthLayer).query().sdf\n",
    "\n",
    "# summarize the data by Acres\n",
    "oldGrowthDataSummary = oldGrowthData.groupby('SeralStage').agg({'Acres': 'sum'}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVeg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# colors of the veg types\n",
    "colors = ['#d7d79e','#9ed7c2','#cdf57a','#b4d79e', \n",
    "          '#ff0000', '#a5f57a','#00a820','#df73ff', \n",
    "          '#3e72b0','#2f3f56', '#a8a800']\n",
    "\n",
    "# current species distribution Use \"TRPA_Veg_Type\" to display the current species distribution\n",
    "speciesLayer = \"https://maps.trpa.org/server/rest/services/Vegetation_Type/MapServer/0\"\n",
    "\n",
    "# get the feature layer as a spatially enabled dataframe\n",
    "dfVeg = FeatureLayer(speciesLayer).query().sdf\n",
    "\n",
    "# summarize the data by Acres\n",
    "dfVeg.TRPA_VegType.replace('', np.nan, inplace=True)\n",
    "dfVegType = dfVeg.groupby(\"TRPA_VegType\")[\"Acres\"].sum().reset_index()\n",
    "\n",
    "df = dfVegType.rename(columns={'TRPA_VegType':'Vegetation Type'})\n",
    "\n",
    "df['Vegetation Type'] = df['Vegetation Type'].replace(['Cushion Plant'],'Cushion Plant/Rocky Outcrop')\n",
    "\n",
    "fig = px.bar(df, y=\"Vegetation Type\", x=\"Acres\", color=\"Vegetation Type\", orientation=\"h\", hover_name=\"Vegetation Type\",\n",
    "             color_discrete_sequence=colors ,\n",
    "             title=\"Vegetation Abundance\"\n",
    "            )\n",
    "\n",
    "fig.update_traces(hovertemplate='<b>%{x:,.0f}</b> acres<extra></extra>')\n",
    "\n",
    "# set style variables\n",
    "template = 'plotly_white'\n",
    "font     = 'Calibri'\n",
    "\n",
    "fig.update_layout(font_family=font,\n",
    "                    template=template,\n",
    "                    showlegend=False,\n",
    "                    hovermode=\"y unified\",\n",
    "                    yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of fire by low, moderate, & high severity by management zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial analysis for fire severity\n",
    "import arcpy\n",
    "\n",
    "# reclass Low Severity flame length raster\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\"):\n",
    "    out_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=r\"F:\\\\GIS\\\\PROJECTS\\\\ForestHealth_Intiative\\\\ThresholdUpdate\\\\Data\\\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbLowSeverity_2022_ACCEL_30m_Tahoe\",\n",
    "        reclass_field=\"Value\",\n",
    "        remap=\"0 0.600000 0;0.600000 1 1\",\n",
    "        missing_values=\"DATA\"\n",
    "    )\n",
    "    out_raster.save(r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_Reclass_Low_60thPercentile\")\n",
    "\n",
    "# convert reclassified raster to polygon\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=r\"Fire Severity\\Low Severity Fire\",\n",
    "    out_polygon_features=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbableLowSeverityFire\",\n",
    "    simplify=\"NO_SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")\n",
    "\n",
    "# identity analysis\n",
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"Boundaries\\Forest Management Zone\",\n",
    "    identity_features=\"FunctionalFire_ProbableLowSeverityFire\",\n",
    "    out_feature_class=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")\n",
    "\n",
    "# Calculate the area in acres for each feature\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=r\"Fire Severity\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# export table to database\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=r\"Fire Severity\\ForestManagementZon_Identity_LowSeverity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_ProbabilityLowSeverityFire_by_ForestManagmentZone\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    sort_field=None\n",
    ")\n",
    "\n",
    "# reclass High Severity flame length raster\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\"):\n",
    "    out_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=r\"F:\\\\GIS\\\\PROJECTS\\\\ForestHealth_Intiative\\\\ThresholdUpdate\\\\Data\\\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbHighSeverity_2022_ACCEL_30m_Tahoe\",\n",
    "        reclass_field=\"Value\",\n",
    "        remap=\"0 0.600000 0;0.600000 1 1\",\n",
    "        missing_values=\"DATA\"\n",
    "    )\n",
    "    out_raster.save(r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_Reclass_High_60thPercentile\")\n",
    "\n",
    "# convert reclassified raster to polygon\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=r\"Fire Severity\\High Severity Fire\",\n",
    "    out_polygon_features=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\FunctionalFire_ProbableHighSeverityFire\",\n",
    "    simplify=\"NO_SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")\n",
    "\n",
    "# identity analysis\n",
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"Boundaries\\Forest Management Zone\",\n",
    "    identity_features=\"FunctionalFire_ProbableHighSeverityFire\",\n",
    "    out_feature_class=r\"F:\\GIS\\PROJECTS\\ForestHealth_Intiative\\ThresholdUpdate\\Data\\ForestHealth_ThresholdUpdate.gdb\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")\n",
    "\n",
    "# Calculate the area in acres for each feature\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=r\"Fire Severity\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# export table to database\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=r\"Fire Severity\\ForestManagementZon_Identity_HighSeverity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_ProbabilityHighSeverityFire_by_ForestManagmentZone\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    sort_field=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "highseverityURL = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/129\"\n",
    "lowseverityURL  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/130\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(highseverityURL)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_highseverity = feature_layer.query().sdf\n",
    "\n",
    "sdf_highseverity.head()\n",
    "# summarize the area of high and low severity fire by name and gridcode\n",
    "highseverity_summary = sdf_highseverity.groupby(['Name', 'gridcode'])['Acres'].sum().reset_index()\n",
    "\n",
    "# reclassify values of gridcode in new field called 'Severity' with 1 = \">60% chance of high severity fire\" and 0 = \"<60% chance of high severity fire\"\n",
    "highseverity_summary['Severity'] = np.where(highseverity_summary['gridcode'] == 1, \">60% chance of high severity fire\", \"<60% chance of high severity fire\")\n",
    "\n",
    "# Plot using Plotly Express to create a stacked bar chart of Severity by Name with the bar chart being 100% stacked\n",
    "fig = px.histogram(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barnorm='percent',barmode='stack')\n",
    "# fig = px.bar(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barmode='stack')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowseverityURL  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/130\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(lowseverityURL)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_lowseverity = feature_layer.query().sdf\n",
    "\n",
    "sdf_lowseverity.head()\n",
    "# summarize the area of high and low severity fire by name and gridcode\n",
    "lowseverity_summary = sdf_lowseverity.groupby(['Name', 'gridcode'])['Acres'].sum().reset_index()\n",
    "\n",
    "# reclassify values of gridcode in new field called 'Severity' \n",
    "lowseverity_summary['Severity'] = np.where(lowseverity_summary['gridcode'] == 1, \">60% chance of low severity fire\", \"<60% chance of low severity fire\")\n",
    "\n",
    "# Plot using Plotly Express to create a stacked bar chart of Severity by Name with the bar chart being 100% stacked\n",
    "fig = px.histogram(lowseverity_summary, x='Name', y='Acres', color='Severity', title='Low Severity Fire by Forest Management Zone', barnorm='percent',barmode='stack')\n",
    "# fig = px.bar(highseverity_summary, x='Name', y='Acres', color='Severity', title='High Severity Fire by Forest Management Zone', barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Moderate Severity Fire does not exist in the service....USFS data is needed to complete the analysis, but they didnt provide it in the data package\n",
    "\n",
    "# we could get at this by doing the math's between low and high severity fire, but that would be a bit of a stretch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres treated for aquatic invasive species. *We could gain additional clarity regarding this indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# EIP Service for Acres Treated\n",
    "eipInvasive = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/15\"\n",
    "\n",
    "df = pd.read_json(eipInvasive)\n",
    "\n",
    "sum_df = df.groupby('IndicatorProjectYear')['IndicatorProjectValue'].cumsum()\n",
    "\n",
    "display(sum_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acres of restored high-quality wetlands and meadows helping to store flood waters. *We are expecting additional clarity regarding this indicator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EIP indicator as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# EIP Service for SEZ Restored or Enhanced\n",
    "eipSEZRestored = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/9\"\n",
    "\n",
    "# GIS of SEZ Enchanced\n",
    "trpaSEZEnhancedRestored = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/126\"\n",
    "# GIS of SEZ Restored\n",
    "trpaSEZRestored = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/127\"\n",
    "# get the data\n",
    "df = pd.read_json(eipSEZRestored)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased number of parcels with Stormwater Best Management Practices (BMPs) improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BMP data as dataframe\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# # EIP Service for BMPs installed\n",
    "# bmpsInstalled = \"https://www.laketahoeinfo.org/WebServices/GetReportedEIPIndicatorProjectAccomplishments/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476/4\"\n",
    "\n",
    "# BMP map service from BMP database\n",
    "bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "\n",
    "# get the data\n",
    "feature_layer = FeatureLayer(bmpsLayer)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bmps = feature_layer.query().sdf\n",
    "\n",
    "# total BMPs installed\n",
    "total_bmps = sdf_bmps['OBJECTID'].count()\n",
    "\n",
    "# filter total BMPs CertificateIssued = 1\n",
    "sdf_bmps_cert = sdf_bmps[sdf_bmps['CertificateIssued'] == 1]\n",
    "\n",
    "# total BMPs installed\n",
    "total_bmps_cert = sdf_bmps_cert['OBJECTID'].count()\n",
    "\n",
    "# create Year column\n",
    "sdf_bmps_cert['Year'] = pd.DatetimeIndex(sdf_bmps_cert['CertDate']).year\n",
    "\n",
    "# total BMPs installed per year\n",
    "total_bmps_cert_year = sdf_bmps_cert.groupby('Year')['OBJECTID'].count().reset_index()\n",
    "\n",
    "# create plotly figure of BMPs installed per year\n",
    "fig = px.bar(total_bmps_cert_year, x='Year', y='OBJECTID', title='BMPs Installed per Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='BMPs Installed')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulutive sum of BMPs installed per year\n",
    "total_bmps_cert_year['Cumulative BMPs Installed'] = total_bmps_cert_year['OBJECTID'].cumsum()\n",
    "# create plotly figure of BMPs installed per year\n",
    "fig = px.bar(total_bmps_cert_year, x='Year', y='Cumulative BMPs Installed', title='BMPs Installed')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Cumulative BMPs Installed')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMP map service from BMP database\n",
    "bmpsLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/121\"\n",
    "# get the data\n",
    "feature_layer = FeatureLayer(bmpsLayer)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bmps = feature_layer.query().sdf\n",
    "\n",
    "# filter total BMPs CertificateIssued = 1\n",
    "sdf_bmps_cert = sdf_bmps[sdf_bmps['CertificateIssued'] == 1]\n",
    "\n",
    "# total developed parcels, use .loc to get EXISTING_LANDUSE does not equal \"Vacant\" or \"Open Space\"\n",
    "parcelsDeveloped = sdf_bmps.loc[~sdf_bmps['EXISTING_LANDUSE'].isin(['Vacant', 'Open Space'])]\n",
    "parcelsDeveloped = parcelsDeveloped['OBJECTID'].count()\n",
    "\n",
    "# total bmps certified by year compared to total developed parcels\n",
    "# create Year column\n",
    "sdf_bmps_cert['Year'] = pd.DatetimeIndex(sdf_bmps_cert['CertDate']).year\n",
    "bmpsCertByYear = sdf_bmps_cert.groupby('Year')['OBJECTID'].count().reset_index()\n",
    "bmpsCertByYear['Cumulative BMPs Installed'] = bmpsCertByYear['OBJECTID'].cumsum()\n",
    "bmpsCertByYear['Developed Parcels'] = parcelsDeveloped\n",
    "bmpsCertByYear['BMPs per Developed Parcel'] = bmpsCertByYear['Cumulative BMPs Installed'] / bmpsCertByYear['Developed Parcels']\n",
    "bmpsCertByYear['BMPs per Developed Parcel'] = bmpsCertByYear['BMPs per Developed Parcel'].round(2)\n",
    "\n",
    "# create plotly figure of BMPs installed per year\n",
    "fig = px.bar(bmpsCertByYear, x='Year', y='BMPs per Developed Parcel', title='BMPs Installed per Developed Parcel')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='% BMPs Installed per Developed Parcel')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create staked bar chart of BMPs installed per year compared to total developed parcels per year but subtracting the BMPs installed from the total developed parcels\n",
    "bmpsCertByYear['Developed Parcels Without a BMP'] = bmpsCertByYear['Developed Parcels'] - bmpsCertByYear['Cumulative BMPs Installed']\n",
    "\n",
    "bmpsCertByYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create staked bar chart of BMPs installed per year compared to total developed parcels per year but subtracting the BMPs installed from the total developed parcels\n",
    "fig = px.bar(bmpsCertByYear, x='Year', y=['Cumulative BMPs Installed', 'Developed Parcels Without a BMP'], title='BMPs Installed per Developed Parcel')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='BMPs Installed per Developed Parcel')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase in square feet of urban development treated by areawide stormwater infrastructure within key watersheds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reqeusted \"Year of Completion\" data for each area wide storm water treatment from Shay. TBD if this is available\n",
    "\n",
    "# area wide storm water treamtent layer # we can't do this analysis without the year of completion data\n",
    "areawideLayer  = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/120\"\n",
    "\n",
    "# developed area layers\n",
    "impervious2010Layer   = \"https://maps.trpa.org/server/rest/services/Impervious_Surface_2010/MapServer\"\n",
    "impervious2019Layer   = \"https://maps.trpa.org/server/rest/services/Impervious_Surface_2019/MapServer\"\n",
    "imperviousChangeLayer = \"https://maps.trpa.org/server/rest/services/Impervious_Surface_Change_2010_to_2019/MapServer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.analysis.Identity(\n",
    "    in_features=r\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.Impervious\\SDE.Impervious_2019\",\n",
    "    identity_features=r\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.EIP\\SDE.Existing_Drainage_Areas\",\n",
    "    out_feature_class=r\"C:\\GIS\\Scratch.gdb\\Impervious_2019_Identity\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    relationship=\"NO_RELATIONSHIPS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=\"Impervious_2019_Identity\",\n",
    "    geometry_property=\"Acres AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"ACRES_US\",\n",
    "    coordinate_system='PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-123.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table=\"Impervious_2019_Identity\",\n",
    "    out_table=r\"F:\\GIS\\DB_CONNECT\\Tabular.sde\\SDE.ClimateResilience_Impervious_Identify_Areawide_ByYear\",\n",
    "    where_clause=\"\",\n",
    "    use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "    field_mapping='FID_Impervious_2019 \"FID_Impervious_2019\" true true false 4 Long 0 0,First,#,Impervious_2019_Identity,FID_Impervious_2019,-1,-1;Feature \"Feature\" true true false 8 Text 0 0,First,#,Impervious_2019_Identity,Feature,0,7;Surface \"Surface\" true true false 4 Text 0 0,First,#,Impervious_2019_Identity,Surface,0,3;FID_Existing_Drainage_Areas \"FID_Existing_Drainage_Areas\" true true false 4 Long 0 0,First,#,Impervious_2019_Identity,FID_Existing_Drainage_Areas,-1,-1;Drainage_Area_Name \"Name\" true true false 100 Text 0 0,First,#,Impervious_2019_Identity,Drainage_Area_Name,0,99;Status \"Status\" true true false 50 Text 0 0,First,#,Impervious_2019_Identity,Status,0,49;Year_Completed \"Year_Completed\" true true false 4 Text 0 0,First,#,Impervious_2019_Identity,Year_Completed,0,3;Acres \"Acres\" true true false 8 Double 0 0,First,#,Impervious_2019_Identity,Acres,-1,-1',\n",
    "    sort_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# REST service for impervious area wide\n",
    "imperviousAreaWide = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/140\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(imperviousAreaWide)\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_impervious = feature_layer.query().sdf\n",
    "\n",
    "# summarize total area of Surface = Hard Surface\n",
    "sdf_impervious_hard = sdf_impervious[sdf_impervious['Surface'] == 'Hard']\n",
    "\n",
    "# summarize the area of hard surface covered by status = completed or active\n",
    "sdf_impervious_hard_summary = sdf_impervious_hard.groupby(['Status', 'Year_Completed'])['Acres'].sum().reset_index()\n",
    "\n",
    "sdf_impervious_hard_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out Status is not ''\n",
    "sdf_impervious_hard_summary = sdf_impervious_hard_summary[sdf_impervious_hard_summary['Status'] != '']\n",
    "# group status active and constructed to completed\n",
    "sdf_impervious_hard_summary['Status'] = sdf_impervious_hard_summary['Status'].replace(['Active', 'Constructed'], 'Completed')\n",
    "\n",
    "# add acres in cumulative sum\n",
    "sdf_impervious_hard_summary['Cumulative Acres'] = sdf_impervious_hard_summary.groupby('Status')['Acres'].cumsum()\n",
    "\n",
    "# ploty figure of impervious area wide by year\n",
    "fig = px.bar(sdf_impervious_hard_summary, x='Year_Completed', y='Cumulative Acres', color='Status', title='Impervious Area Wide by Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Acres of Hard Surface Covered by Yera')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total acreas of surface == hard\n",
    "\n",
    "total_acres = sdf_impervious_hard['Acres'].sum()\n",
    "total_acres\n",
    "\n",
    "# create cumulative sum of acres of status - completed\n",
    "sdf_impervious_hard_summary['Cumulative Acres'] = sdf_impervious_hard_summary['Acres'].cumsum()\n",
    "\n",
    "# subtract area covereed by cumulatve sum from total acres\n",
    "\n",
    "sdf_impervious_hard_summary['Acres Remaining'] = total_acres - sdf_impervious_hard_summary['Cumulative Acres']\n",
    "\n",
    "sdf_impervious_hard_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploty figure of impervious area wide by year\n",
    "fig = px.bar(sdf_impervious_hard_summary, x='Year_Completed', y=['Cumulative Acres', 'Acres Remaining'], title='Impervious Area Wide by Year')\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Acres of Hard Surface Covered by Yera')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of housing units in town centers and share of affordable housing in Town Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# town center layer\n",
    "towncenterLayer = \"https://maps.trpa.org/server/rest/services/LocalPlan/MapServer/2\"\n",
    "# parcel development history layer for 2012, and 2018-2022 # 2021 and 2023 coming soon. other years are unknown\n",
    "parcelDevelopmentHistoryLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/17\"\n",
    "# deed restricted housing layer\n",
    "deedRestrictedHousingLayer = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature layer as a spatially enabled dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in share of homes with electric or solar energy fuel compared to oil/gas over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kathleen did this. need to get the data in our database and web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of deed-restricted affordable, moderate, and achievable units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# deed restriction service\n",
    "deedRestrictionService = \"https://www.laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\"\n",
    "\n",
    "# read in deed restricted parcels\n",
    "dfDeed = pd.read_json(deedRestrictionService)\n",
    "\n",
    "# filter out deed restrictions that are not affordable housing\n",
    "dfDeed = dfDeed.loc[dfDeed['DeedRestrictionType'].isin(['Affordable Housing', 'Achievable Housing', 'Moderate Income Housing'])]\n",
    "\n",
    "# create year column\n",
    "dfDeed['Year'] = dfDeed['RecordingDate'].str[-4:]\n",
    "\n",
    "# group by type and year\n",
    "df = dfDeed.groupby(['DeedRestrictionType', 'Year']).size().reset_index(name='Total')\n",
    "\n",
    "# sort by year\n",
    "df.sort_values('Year', inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df = df.rename(columns={'DeedRestrictionType': 'Type', 'Year': 'Year', 'Total': 'Count'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Type': np.repeat(df['Type'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Type'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Type', 'Year'], how='left')\n",
    "\n",
    "# Replace NaN values in 'Count' with 0\n",
    "df['Count'] = df['Count'].fillna(0)\n",
    "\n",
    "# Ensure 'Count' is of integer type\n",
    "df['Count'] = df['Count'].astype(int)\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Count'] = df.sort_values('Year').groupby('Type')['Count'].cumsum()\n",
    "\n",
    "# create cumuluative total of deed restricted parcels by type\n",
    "fig = px.line(df, x=\"Year\", y=\"Cumulative Count\", color=\"Type\", title=\"Deed Restricted Parcels\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of renewable energy as a share of total energy used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kathleen did this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total transit ridership by transit systems\n",
    "* https://www.laketahoeinfo.org/Indicator/Detail/46/Overview\n",
    "* this doesn't work yet. Talking to ESA to get web service stood up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# Data not avaialble from LTinfo yet. Shannon is working on a service for this. I will get the data from Kira as a placeholder for now.\n",
    "# indicator data saved from Kira's email\n",
    "eipTransit = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/131\"\n",
    "\n",
    "# read in spatial enabled dataframe\n",
    "dfTransit = FeatureLayer(eipTransit).query().sdf\n",
    "\n",
    "# drop ObjectID\n",
    "dfTransit = dfTransit.drop(columns=['OBJECTID'])\n",
    "# stack data by month\n",
    "dfTransit = dfTransit.melt(id_vars=['MONTH'], var_name='Name', value_name='Ridership')\n",
    "\n",
    "# create Year field from last two characters of month but add 20 prefix\n",
    "dfTransit['Year'] = '20' + dfTransit['MONTH'].str[-2:]\n",
    "# strip the last three characters from month\n",
    "dfTransit['Month'] = dfTransit['MONTH'].str[:-3]\n",
    "# drop MONTH\n",
    "dfTransit = dfTransit.drop(columns=['MONTH'])\n",
    "# make the values in Month the real names of the months\n",
    "dfTransit['Month'] = dfTransit['Month'].replace(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], \n",
    "                                                ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
    "\n",
    "\n",
    "# create a Date type field of Month and Year\n",
    "dfTransit['Date'] = dfTransit['Month'] + ' ' + dfTransit['Year']\n",
    "# convert Date to datetime\n",
    "dfTransit['Date'] = pd.to_datetime(dfTransit['Date'], format='%B %Y')\n",
    "dfTransit = dfTransit.sort_values('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plotly figure of transit ridership by date \n",
    "fig = px.line(dfTransit, x=\"Date\", y=\"Ridership\", color=\"Name\", title=\"Transit Ridership\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily per capita Vehicles Miles Traveled (VMT) and progress towards VMT target. The RTP (2021) identifies a Daily per capita VMT target set at a 6.8 percent reduction from 2018 levels by 2045 (2018 per capita daily VMT is 12.48, goal is 11.63)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh coming 2/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage of electric bus routes and alternative fuel, such as EV charging for vehicles and bicycles\n",
    "* Primary source: https://www.plugshare.com/ requested access to their API\n",
    "* Secondary (if needed to cross-check): https://afdc.energy.gov/stations/#/find/nearest\n",
    "\n",
    "* current in-house data: https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no real info on this right now. Will checking with Kira on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline mode share and weekday or seasonal variation. The Tahoe RTP (2021) includes the following Non-Auto Mode Share Target: Improve average non-auto mode share calculated from the two most recent TRPA travel survey results; the current performance on target at 24.5% (2018-20 average) up from 18% in 2014-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh coming 2/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transportation access in priority communities. The Tahoe RTP (2021) includes a target to increase access to each mode for Priority communities to 100% by 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will check in with Kira on this again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased lane miles of low-stress bicycle facilities (both bicycle and pedestrian facilities that are considered comfortable enough for all users and abilities, and implicitly measures active transportation network connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Count'] = df.sort_values('Year').groupby(['Year', 'Class'])['Miles'].cumsum()\n",
    "\n",
    "# get rid of all columns except for Year, Class, and Cumulative Count\n",
    "df = df[['Year', 'Class', 'Cumulative Count']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of all columns except for Year, Class, and Cumulative Count\n",
    "df = df[['Year', 'Class', 'Cumulative Miles']]\n",
    "# get all rows where Year = 2006\n",
    "df_2006 = df[df['Year'] == 2006]\n",
    "# display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "\n",
    "# bring in 2005 data  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "\n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# \n",
    "df =df.groupby(['Year', 'Class'])['Miles'].sum().reset_index()\n",
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the service URL\n",
    "bikelaneService = \"https://maps.trpa.org/server/rest/services/Transportation/MapServer/3\"\n",
    "\n",
    "# Create a FeatureLayer object\n",
    "feature_layer = FeatureLayer(bikelaneService)\n",
    "\n",
    "# Query the feature layer and convert the result to a Spatially Enabled DataFrame\n",
    "sdf_bikelane = feature_layer.query().sdf\n",
    "\n",
    "# recalc miles field from shape length\n",
    "sdf_bikelane.MILES = sdf_bikelane[\"Shape.STLength()\"]/ 1609.34\n",
    "\n",
    "# filter for CLASS = 1 2 or 3\n",
    "filtered_sdf_bikelane = sdf_bikelane[sdf_bikelane['CLASS'].isin(['1', '2', '3'])]\n",
    "\n",
    "# fix bad values\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2010', ' before 2010'], '2010')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['before 2006','Before 2006','BEFORE 2006'], '2006')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace([' 2014'], '2014')\n",
    "filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'] = filtered_sdf_bikelane.loc[:, 'YR_OF_CONS'].replace(['2007 (1A) 2008 (1B)'], '2008')\n",
    "\n",
    "# drop rows with <NA> values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane.dropna(subset=['YR_OF_CONS'])\n",
    "# drop rows with 'i dont know' or 'UNKNOWN' values\n",
    "filtered_sdf_bikelane = filtered_sdf_bikelane[~filtered_sdf_bikelane['YR_OF_CONS'].isin(['i dont know', 'UNKNOWN'])]\n",
    "\n",
    "# rename columns\n",
    "df = filtered_sdf_bikelane.rename(columns={'CLASS': 'Class', 'YR_OF_CONS': 'Year', 'MILES': 'Miles'})\n",
    "\n",
    "# Create a DataFrame with all possible combinations of 'Type' and 'Year'\n",
    "df_all = pd.DataFrame({\n",
    "    'Class': np.repeat(df['Class'].unique(), df['Year'].nunique()),\n",
    "    'Year': df['Year'].unique().tolist() * df['Class'].nunique()\n",
    "})\n",
    "\n",
    "# Merge the new DataFrame with the original one to fill in the gaps of years for each type with NaN values\n",
    "df = pd.merge(df_all, df, on=['Class', 'Year'], how='left')\n",
    "\n",
    "# add 2005 to the Year field for Class 1 2, and 3\n",
    "dict = {'Class':['1', '2', '3'], \n",
    "        'Year':['2005', '2005', '2005'], \n",
    "        'Miles':[0, 0, 0] \n",
    "       } \n",
    "  \n",
    "df2 = pd.DataFrame(dict) \n",
    "\n",
    "# bring in 2005 data  \n",
    "df = pd.concat([df, df2], ignore_index = True) \n",
    "\n",
    "# cast Year as integer\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# sort by year and miles\n",
    "df.sort_values(['Year', 'Miles'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'MILES' with 0\n",
    "df['Miles'] = df['Miles'].fillna(0)\n",
    "\n",
    "# create grouped dataframe\n",
    "df = df.groupby(['Year', 'Class'])['Miles'].sum().reset_index()\n",
    "\n",
    "# Recalculate 'Cumulative Count' as the cumulative sum of 'Count' within each 'Type' and 'Year'\n",
    "df['Cumulative Miles'] = df.sort_values('Year').groupby('Class')['Miles'].cumsum()\n",
    "\n",
    "# create cumuluative total of miles of bike lanes by Class\n",
    "fig = px.line(df, x=\"Year\", y=\"Cumulative Miles\", color=\"Class\", title=\"Miles of Bike Lane by Type\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Household Income (MHI) by community area (to be determined) and disaggregated by remote and non-remote workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census table\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing costs (median home sales price and rental rates, by jurisdiction); include cost per unit and cost per square foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sean is getting COSTAR and Property Radar data for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing tenure (rented full-time, owner-occupied, second home), disaggregated by race, ethnicity, and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of workers who commute into the basin, origin demographics, distance travelled, difference in travel time by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transient Occupancy Tax revenue and changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new data from Josh coming 2/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent employment and median wages by sector and overall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to recreation sites, fresh food, and healthcare for zero-vehicle households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wiht Kira on this. Will make a map of what we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firewise communities in the Tahoe basin, coolling centers/heating centers, resources, and emergency infrastructure (medical centers with supplies, fire response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population disaggregated by race and ethnicity, age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number/share of households with access and functional needs (These can be referred to as vulnerable populations including populations such as persons with disabilities, older adults, children, limited English proficiency, and transportation disadvantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "censusTable = \"https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trpa-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
