from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
from meteostat import Daily, Point

from utils import convert_to_utc, get_fs_data, read_file, scatterplot, stackedbar, trendline


# get Greenhouse Gas data
def get_data_greenhouse_gas():
    return get_fs_data(
        "https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/127"
    )


# plot Greenhouse Gas data
def plot_greenhouse_gas(df):
    trendline(
        df,
        path_html="html/1.1.a_Greenhouse_Gas.html",
        div_id="1.1.a_greenhouse_gas",
        x="Year",
        y="MT_CO2",
        color="Category",
        color_sequence=["#023f64", "#7ebfb5", "#a48352", "#fc9a61", "#A48794", "#b83f5d"],
        sort="Year",
        orders=None,
        x_title="Year",
        y_title="Amount of CO2 (MT CO2e)",
        format=",.0f",
        custom_data=["Category"],
        hovertemplate="<br>".join(
            ["<b>%{y:,.0f} MT CO2e</b> were generated by", "<i>%{customdata[0]}</i> sources"]
        )
        + "<extra></extra>",
        markers=True,
        hover_data=None,
        tickvals=None,
        ticktext=None,
        tickangle=None,
        hovermode="x unified",
        additional_formatting=dict(
                                # title="Green House Gas Inventory",
                                legend_title_text="Green House Gas Inventory",
                                legend=dict(
                                orientation="h",
                                entrywidth=120,
                                yanchor="bottom",
                                y=1.05,
                                xanchor="right",
                                x=1,
                            )
                            )

    )

# get purple air data from CSV
def get_data_purple_air():
    df = read_file("data/daily_averaged_values.csv")
    df["AQI"] = np.where(
        df["daily_mean_25pm"] > 350.5,
        calcAQI(df["daily_mean_25pm"], 500, 401, 500.4, 350.5),
        np.where(
            df["daily_mean_25pm"] > 250.5,
            calcAQI(df["daily_mean_25pm"], 400, 301, 350.4, 250.5),
            np.where(
                df["daily_mean_25pm"] > 150.5,
                calcAQI(df["daily_mean_25pm"], 300, 201, 250.4, 150.5),
                np.where(
                    df["daily_mean_25pm"] > 55.5,
                    calcAQI(df["daily_mean_25pm"], 200, 151, 150.4, 55.5),
                    np.where(
                        df["daily_mean_25pm"] > 35.5,
                        calcAQI(df["daily_mean_25pm"], 150, 101, 55.4, 35.5),
                        np.where(
                            df["daily_mean_25pm"] > 12.1,
                            calcAQI(df["daily_mean_25pm"], 100, 51, 35.4, 12.1),
                            np.where(
                                df["daily_mean_25pm"] >= 0,
                                calcAQI(df["daily_mean_25pm"], 50, 0, 12, 0),
                                9999999,
                            ),
                        ),
                    ),
                ),
            ),
        ),
    )
    df["moving_avg"] = df["AQI"].rolling(window=7).mean()
    # df["time_stamp"] = pd.to_datetime(df["time_stamp"])
    # df.set_index('time_stamp', inplace=True)
    # weekly_avg = df.resample('W').mean().reset_index()
    return df


# get purple air data from web service
def get_data_purple_air_TRPA():
    # Purple Air data
    purpleAirURL = "https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/143"
    # get data from the web service
    dfPurpleAir = get_fs_data(purpleAirURL)
    # groupby date and get the mean of pm25
    dfAir = dfPurpleAir.groupby("date")["mean_pm25"].mean().reset_index()
    # change column name to Date and PM 2.5 (ug/m3)
    dfAir = dfAir.rename(columns={"date": "Date", "mean_pm25": "PM 2.5 (ug/m3)"})
    # Apply the function to the column
    dfAir["Date"] = dfAir["Date"].apply(convert_to_utc)
    # # convert Date to str
    dfAir["Date"] = dfAir["Date"].dt.strftime("%m/%d/%Y")
    # # convert Date to datetime
    dfAir["Date"] = pd.to_datetime(dfAir["Date"], format="%m/%d/%Y")
    return dfAir


# get fire data
def get_fire_data():
    # wildfire url CALFIRE
    fireStartTable = "https://services1.arcgis.com/jUJYIo9tSA7EHvfZ/arcgis/rest/services/California_Fire_Perimeters/FeatureServer/0"
    # Purple Air data hosted on TRPA's Enterprise Geodatabase
    purpleAirURL = "https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/143"
    # get data from the web service
    dfPurpleAir = get_fs_data(purpleAirURL)
    dfFire = get_fs_data(fireStartTable)
    # remove nulls from ALARM_DATE
    dfFire = dfFire.dropna(subset=["ALARM_DATE"])
    # remove negative numbers in ALARM_DATE
    dfFire = dfFire[dfFire["ALARM_DATE"] > 0]
    # groupby date and get the mean of pm25
    dfAir = dfPurpleAir.groupby("date")["mean_pm25"].mean().reset_index()
    # Apply the function to the column
    dfFire["Date"] = dfFire["ALARM_DATE"].apply(convert_to_utc)
    # convert Date to month day year
    dfFire["Date"] = dfFire["Date"].dt.strftime("%m/%d/%Y")
    # convert date to datetime
    dfFire["Date"] = pd.to_datetime(dfFire["Date"], format="%m/%d/%Y")
    # filter date to 2018 or later
    dfFire = dfFire[dfFire["Date"] >= "01/01/2018"]
    # filter FIRE_NAME is ['CALDOR', 'TAMARACK', 'FERGUSON', 'MOSQUITO', 'LOYALTON']
    dfFire = dfFire.loc[
        dfFire["FIRE_NAME"].isin(["CALDOR", "TAMARACK", "FERGUSON", "MOSQUITO", "LOYALTON"])
    ]
    # only keep FIRE_NAME, GIS_ACRES, and Date
    dfFire = dfFire[["FIRE_NAME", "GIS_ACRES", "Date"]]
    # rename columns
    dfFire = dfFire.rename(columns={"FIRE_NAME": "Fire", "GIS_ACRES": "Acres"})
    # change column name to Date and PM 2.5 (ug/m3)
    dfAir = dfAir.rename(columns={"date": "Date", "mean_pm25": "PM 2.5 (ug/m3)"})
    # Apply the function to the column
    dfAir["Date"] = dfAir["Date"].apply(convert_to_utc)
    # # convert Date to str
    dfAir["Date"] = dfAir["Date"].dt.strftime("%m/%d/%Y")
    # # convert Date to datetime
    dfAir["Date"] = pd.to_datetime(dfAir["Date"], format="%m/%d/%Y")

    # merge with sdfPUrplAir on Date
    df = dfFire.merge(dfAir, on="Date", how="left")
    return df


# html/1.2.a_Purple_Air_v2.html
def plot_purple_air_fire(dfAir,dfFire):

    # creat a plotly express line chart
    fig = px.line(dfAir, x="Date", y="PM 2.5 (ug/m3)", title="Purple Air PM2.5")

    fig.update_layout(
        hovertemplate="<br>".join(["<b>%{y:,.0f}</b> AQI", "<i>seven day rolling average</i>"])
        + "<extra></extra>"
    )

    # add scatter trace to figure of points of dfMerge by date and mean_pm25
    fig.add_trace(
        go.Scatter(
            x=dfFire["Date"],
            y=dfFire["PM 2.5 (ug/m3)"],
            mode="markers",
            name="Fire Start Date",
            customdata=dfFire[["Fire", "Acres"]],
            hovertemplate="<br>".join(
                [
                    "<b>%{customdata[0]}</b> fire started",
                    "<i>%{x}</i> and burned",
                    "<i>%{customdata[1]:,.0f} acres</i>",
                ]
            )
            + "<extra></extra>",
        )
    )

    # make the scatter plot markers larger
    fig.update_traces(marker=dict(size=12))

    # label points by FIRE_NAME
    for i, txt in enumerate(dfFire['Fire']):
        fig.add_annotation(x=dfFire['Date'].iloc[i], y=dfFire['PM 2.5 (ug/m3)'].iloc[i],
                                text=txt+" FIRE",
                                showarrow=True,
                                align="center",
                                arrowhead=1,
                                # arrowsize=1,
                                # arrowwidth=2,
                                arrowcolor="#636363",
                                ax=10,
                                ay=-20,
                                bordercolor="#c7c7c7",
                                borderwidth=1,
                                borderpad=2,
                                bgcolor="#ff7f0e",
                                opacity=0.8
                                )


    # plot variables
    path_html = "html/1.2.a_Purple_Air_v2.html"
    div_id = "1.2.a_Purple_Air_v2"
    x = "time_stamp"
    y = "moving_avg"
    color = "#FF5733"
    color_sequence = ["#023f64"]
    sort = "time_stamp"
    orders = None
    x_title = "Date"
    y_title = "AQI (rolling average)"
    format = ",.0f"
    hovermode = "x unified"
    config = {"displayModeBar": False}

    fig.update_layout(
        yaxis=dict(title=y_title),
        xaxis=dict(title=x_title, showgrid=False),
        hovermode=hovermode,
        template="plotly_white",
        dragmode=False,
        showlegend=False,
    )

    # fig.update_traces(hovertemplate=hovertemplate)
    fig.update_yaxes(tickformat=format)

    # set color of scatter marker
    fig.update_traces(marker=dict(color=color))
    # set color of line
    fig.update_traces(line=dict(color=color_sequence[0]))

    fig.write_html(config=config, file=path_html, include_plotlyjs="directory", div_id=div_id)


def plot_purple_air(df):
    trendline(
        df,
        path_html="html/1.2.a_Purple_Air.html",
        div_id="1.2.a_Purple_Air",
        x="time_stamp",
        y="moving_avg",
        color=None,
        color_sequence=["#023f64"],
        sort="time_stamp",
        orders=None,
        x_title="Time",
        y_title="AQI (rolling average)",
        markers=False,
        hover_data=None,
        tickvals=None,
        ticktext=None,
        tickangle=None,
        format=",.0f",
        hovermode="x",
        custom_data=None,
        hovertemplate="%{y:,.0f}",
        additional_formatting=None,
    )


# get secchi depth data
def get_data_secchi_depth():
    return get_fs_data(
        "https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/128"
    )


# A pretty specific graph
def plot_secchi_depth(df):
    config = {"displayModeBar": False}
    # convert everything to feet
    df["annual_average"] = df["annual_average"] * 3.28084
    df["F5_year_average"] = df["F5_year_average"] * 3.28084

    fig = px.scatter(
        df, x="year", y="annual_average", trendline="ols", color_discrete_sequence=["#023f64"]
    )
    fig.update_traces(marker=dict(size=8))
    fig.update_layout(
        yaxis=dict(title="Secchi Depth (feet)"),
        xaxis=dict(title="Year", showgrid=False),
        template="plotly_white",
        hovermode="x unified",
        dragmode=False,
        legend=dict(
            orientation="h",
            entrywidth=125,
            # entrywidthmode="fraction",
            yanchor="bottom",
            y=1.05,
            xanchor="right",
            x=1,
            # xref="container",
            # yref="container"
        ),
    )
    fig.update_yaxes(autorange="reversed", autorangeoptions=dict(include=0))
    fig.add_trace(
        px.line(df, x="year", y="F5_year_average", color_discrete_sequence=["#208385"]).data[0]
    )
    fig.data[0].name = "Annual Average"
    fig.data[0].showlegend = True
    fig.data[1].name = "Trendline"
    fig.data[1].showlegend = True
    fig.data[2].name = "5-Year Average"
    fig.data[2].showlegend = True
    fig.update_traces(hovertemplate="%{y:.1f} ft")

    fig.write_html(
        config=config,
        file="html/1.3.c_Secchi_Depth.html",
        include_plotlyjs="directory",
        div_id="1.3.c_Secchi_Depth",
    )


# get air quality data
def get_air_quality():
    data = get_fs_data("https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/46")
    df = data[data["Include_in_Trend_Analysis"] == "Yes"]
    return df


# html\1.2.a_Air_Quality_CO.html
# html\1.2.a_Air_Quality_O3.html
# html\1.2.a_Air_Quality_PM10.html
# html\1.2.a_Air_Quality_PM2.5.html
def plot_air_quality(df):
    # html\1.2.a_Air_Quality_CO.html
    co = df[df["Pollutant"] == "CO"]
    scatterplot(
        df=co,
        path_html="html/1.2.a_Air_Quality_CO.html",
        div_id="1.2.a_Air_Quality_CO",
        x="Year",
        y="Value",
        y2="Threshold_Value",
        color="Site",
        color_sequence=["#FC9A62", "#F9C63E", "#632E5A", "#A48352", "#BCEDB8"],
        y_title="CO (ppm)",
        x_title="Year",
        hovertemplate="%{y:.2f}",
        hovermode="x unified",
        legend_number=5,
        legend_otherline="Threshold",
        additional_formatting=dict(
                        title="Highest 8-Hour Average Concentration of Carbon Monoxide",
                        # legend_title_text="Highest 8-Hour Average Concentration of Carbon Monoxide",
                        legend=dict(
                        orientation="h",
                        entrywidth=190,
                        yanchor="bottom",
                        y=0.95,
                        xanchor="right",
                        x=1,
                    )
                    ),

    )
    # html\1.2.a_Air_Quality_O3.html
    o3 = df[df["Pollutant"] == "O3"]
    scatterplot(
        df=o3,
        path_html="html/1.2.a_Air_Quality_O3.html",
        div_id="1.2.a_Air_Quality_O3",
        x="Year",
        y="Value",
        y2="Threshold_Value",
        color="Site",
        color_sequence=[
            "#FC9A62",
            "#7EBFB5",
            "#632E5A",
            "#023F64",
            "#A48352",
            "#F9C63E",
            "#B83F5D",
            "#749099",
            "#A48794",
        ],
        y_title="Ozone (ppm)",
        x_title="Year",
        hovertemplate="%{y:.2f}",
        hovermode="x unified",
        legend_number=10,
        legend_otherline="Threshold",
        additional_formatting=dict(
                # title="Carbon Monoxide",
                legend_title_text="Highest 1-Hour Average Concentration",
                legend=dict(
                orientation="h",
                entrywidth=190,
                yanchor="bottom",
                y=1.05,
                xanchor="right",
                x=1,
            )
            ),
    )
    # PM10
    pm10 = df[(df["Pollutant"] == "PM10") & (df["Statistic"] == "HIGH 24 HR")]
    scatterplot(
        df=pm10,
        path_html="html/1.2.a_Air_Quality_PM10.html",
        div_id="1.2.a_Air_Quality_PM10",
        x="Year",
        y="Value",
        y2="Threshold_Value",
        color="Site",
        color_sequence=["#FC9A62"],
        y_title="PM10",
        x_title="Year",
        hovertemplate="%{y:.2f}",
        hovermode="x unified",
        legend_number=2,
        legend_otherline="Threshold",
        additional_formatting=dict(
                # title="Carbon Monoxide",
                legend_title_text="Highest 24-Hour Average Concentration",
                legend=dict(
                orientation="h",
                entrywidth=190,
                yanchor="bottom",
                y=1.05,
                xanchor="right",
                x=1,
            )
            ),
    )
    # PM2.5
    pm25 = df[df["Pollutant"] == "PM2.5"]
    scatterplot(
        df=pm25,
        path_html="html/1.2.a_Air_Quality_PM2.5.html",
        div_id="1.2.a_Air_Quality_PM2.5",
        x="Year",
        y="Value",
        y2="Threshold_Value",
        color="Site",
        color_sequence=["#FC9A62"],
        y_title="PM2.5",
        x_title="Year",
        hovertemplate="%{y:.2f}",
        hovermode="x unified",
        legend_number=2,
        legend_otherline="Threshold",
        additional_formatting=dict(
                # title="Carbon Monoxide",
                legend_title_text="3 Year 24-Hour Average Concentration",
                legend=dict(
                orientation="h",
                entrywidth=190,
                yanchor="bottom",
                y=1.05,
                xanchor="right",
                x=1,
            )
            ),
    )


def calcAQI(Cp, Ih, Il, BPh, BPl):
    a = Ih - Il
    b = BPh - BPl
    c = Cp - BPl
    val = round((a / b) * c + Il)
    return val


def get_data_lake_level(days):
    site_number = 10337000

    # Calculate the start and end dates based on the selected time range
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)

    start_date_str = start_date.strftime("%Y-%m-%d")
    end_date_str = end_date.strftime("%Y-%m-%d")

    url = f"https://waterservices.usgs.gov/nwis/iv/?format=json&sites={site_number}&parameterCd=00065&startDT={start_date_str}&endDT={end_date_str}"

    response = requests.get(url)
    data = response.json()

    time_series_data = data["value"]["timeSeries"][0]["values"][0]["value"]

    df = pd.DataFrame(time_series_data)
    df["dateTime"] = pd.to_datetime(df["dateTime"], utc=True)
    df["value"] = pd.to_numeric(df["value"])
    df["value"] = df["value"] + 6220
    weekly = df.groupby(pd.Grouper(key="dateTime", freq="W"))["value"].mean().reset_index()
    return weekly


def plot_lake_level(df):
    trendline(
        df,
        path_html="html/1.3.a_Lake_Level.html",
        div_id="1.3.a_Lake_Level",
        x="dateTime",
        y="value",
        color=None,
        color_sequence=["#023f64"],
        sort="dateTime",
        orders=None,
        x_title="Time",
        y_title="Water Level (ft)",
        hovertemplate="%{y:,.0f}",
        format=",.0f",
        markers=False,
        hover_data=None,
        tickvals=None,
        ticktext=None,
        tickangle=None,
        hovermode="x",
    )


def plot_lake_level_with_high_water_mark(df):
    path_html = "html/1.3.a_Lake_Level.html"
    div_id = "1.3.a_Lake_Level"
    x = "dateTime"
    y = "value"
    color = None
    color_sequence = ["#023f64"]
    sort = "dateTime"
    orders = None
    x_title = "Date"
    y_title = "Water Level (feet)"
    hovertemplate = "%{y:,.0f} ft"
    format = ",.0f"
    tickvals = None
    ticktext = None
    tickangle = None
    hovermode = "x unified"
    df = df.sort_values(by=sort)
    config = {"displayModeBar": False}
    # create figure
    fig = go.Figure()
    # add water level trace
    fig.add_trace(
        go.Scatter(
            x=df[x],
            y=df[y],
            mode="lines",
            name="Water Level",
            line=dict(color="#023f64"),
            # fill="tonexty",
            # line_color="#023f64",
            # fillpattern=dict(fgcolor='#023f64', fillmode='replace', shape="x"),
        )
    )

    # define field/value for high water mark and low water mark
    df["High Water Mark"] = 6229
    df["Low Water Mark"] = 6223

    # add high water mark trace
    fig.add_trace(
        go.Scatter(
            x=df["dateTime"],
            y=df["High Water Mark"],
            name="High Water ",
            line=dict(
                color="#023f64", width=1, dash="dashdot"
            ),  # dash options include 'dash', 'dot', and 'dashdot'
        )
    )
    # add natural rim trace
    fig.add_trace(
        go.Scatter(
            x=df["dateTime"],
            y=df["Low Water Mark"],
            name="Natural Rim",
            line=dict(color="#023f64", width=1, dash="dot"),
        )
    )
    # update layout
    fig.update_layout(
        yaxis=dict(title=y_title),
        xaxis=dict(title=x_title, showgrid=False),
        hovermode=hovermode,
        template="plotly_white",
        dragmode=False,
        legend=dict(
            orientation="h",
            entrywidth=100,
            # entrywidthmode="fraction",
            yanchor="bottom",
            y=1.05,
            xanchor="right",
            x=1,
        ),
    )
    # fig.update_traces(name="High Water Mark", showlegend=False)
    # fig.update_traces(name="Low Water Mark", showlegend=False)
    fig.update_traces(hovertemplate=hovertemplate)
    fig.update_yaxes(tickformat=format)
    fig.update_xaxes(
        tickvals=tickvals,
        ticktext=ticktext,
        tickangle=tickangle,
    )
    # write figure to html
    fig.write_html(
        config=config,
        file=path_html,
        include_plotlyjs="directory",
        div_id=div_id,
    )


def get_data_lake_temp():
    lakeTempURL = "https://tepfsail50.execute-api.us-west-2.amazonaws.com/v1/report/ns-station-range?rptdate=20240130&rptend=20240202&id=4"
    response = requests.get(lakeTempURL)
    df = pd.DataFrame(response.json())
    df["LS_Temp_Avg"] = df["LS_Temp_Avg"].astype(float)
    return df


def get_all_temp_midlake():
    # get start/end dates for the last year
    start = datetime.now() - timedelta(days=365)
    start = start.strftime("%Y%m%d")
    end = datetime.now().strftime("%Y%m%d")
    dfMerge = pd.DataFrame()
    ids = [1, 2, 3, 4]
    for id in ids:
        lakeTempURL = f"https://tepfsail50.execute-api.us-west-2.amazonaws.com/v1/report/nasa-tb?rptdate={start}&rptend={end}&id={id}"
        # get all data from lake temp URL using f string
        response = requests.get(lakeTempURL)
        df = pd.DataFrame(response.json())
        # concat dataframes to dfMerge
        dfMerge = pd.concat([dfMerge, df])
        # convert LS_Temp_Avg to float and farenheit
        dfMerge["RBR_0p5_m"] = dfMerge["RBR_0p5_m"].astype(float)
        dfMerge["RBR_0p5_F"] = dfMerge["RBR_0p5_m"] * 9 / 5 + 32
    # get the mean of all sites by date/time
    df = dfMerge.groupby("TmStamp")["RBR_0p5_F"].mean().reset_index()
    return df


def get_all_temp_shore():
    # get all data from lake temp URL
    start = datetime.now() - timedelta(days=365)
    start = start.strftime("%Y%m%d")
    end = datetime.now().strftime("%Y%m%d")

    dfMerge = pd.DataFrame()
    ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    for id in ids:
        lakeTempURL = f"https://tepfsail50.execute-api.us-west-2.amazonaws.com/v1/report/ns-station-range?rptdate={start}&rptend={end}&id={id}"
        # get all data from lake temp URL using f string
        response = requests.get(lakeTempURL)
        df = pd.DataFrame(response.json())
        # concat dataframes to dfMerge
        dfMerge = pd.concat([dfMerge, df])
        # convert LS_Temp_Avg to float and farenheit
        dfMerge["LS_Temp_Avg"] = dfMerge["LS_Temp_Avg"].astype(float)
        dfMerge["LS_Temp_Avg_F"] = dfMerge["LS_Temp_Avg"] * 9 / 5 + 32
    # get the mean of all sites by date/time
    df = dfMerge.groupby("TmStamp")["LS_Temp_Avg_F"].mean().reset_index()
    return df


def plot_lake_temp_midlake(df):
    trendline(
        df,
        path_html="html/1.3.b_Lake_Temp.html",
        div_id="1.3.b_Lake_Temp",
        x="TmStamp",
        y="RBR_0p5_F",
        color=None,
        color_sequence=["#023f64"],
        sort="TmStamp",
        orders=None,
        x_title="Date",
        y_title="Average Lake Surface Temperature (F)",
        format=".1f",
        hovertemplate="%{y:.2f} F",
        markers=False,
        hover_data=None,
        tickvals=None,
        ticktext=None,
        tickangle=None,
        hovermode="x unified",
    )


def get_data_precip():
    # snowlab precip data
    url = "https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/145"
    data = get_fs_data(url)

    # cast to float
    data["Pct_of_Precip_as_Snow"] = data["Pct_of_Precip_as_Snow"].astype(float)
    data["Pct_of_Precip_as_Rain"] = data["Pct_of_Precip_as_Rain"].astype(float)

    # new fields for total snow and rain from pct fields
    data["Daily_Precip_Rain_mm"] = data.Full_Day_Total_Precip_mm * (
        data.Pct_of_Precip_as_Rain / 100
    )
    data["Daily_Precip_Snow_mm"] = data.Full_Day_Total_Precip_mm * (
        data.Pct_of_Precip_as_Snow / 100
    )

    # drop rows for summer months?
    # data = data[~data.Month_Year.str.endswith(('05', '06', '07', '08', '09'))]

    # group by year and sum the daily precip fields
    dfYearly = (
        data.groupby("Year")
        .agg({"Daily_Precip_Rain_mm": "sum", "Daily_Precip_Snow_mm": "sum"})
        .reset_index()
    )
    dfYearly["Total_Precip_mm"] = (
        dfYearly["Daily_Precip_Rain_mm"] + dfYearly["Daily_Precip_Snow_mm"]
    )

    # create percent fields
    dfYearly["% Rain"] = (dfYearly["Daily_Precip_Rain_mm"] / dfYearly["Total_Precip_mm"]) * 100
    dfYearly["% Snow"] = (dfYearly["Daily_Precip_Snow_mm"] / dfYearly["Total_Precip_mm"]) * 100

    # drop all years before 1987 (no data)
    df = dfYearly[dfYearly["Year"] >= 1987]
    return df


def plot_precip(df):
    stackedbar(
        df,
        path_html="html/1.3.d_Precip.html",
        div_id="1.3.d_Precip",
        x="Year",
        y=["% Snow", "% Rain"],
        facet=None,
        color=None,
        color_sequence=["#BFD7ED", "#60A3D9"],
        orders=None,
        x_title="Year",
        y_title="% of Precipitation",
        hovertemplate="%{y:,.0f}",
        hovermode="x unified",
        orientation=None,
        format=",.0f",
    )


def get_data_temp():
    # meteostat data
    # Set time period
    start = datetime(2003, 1, 1)
    end = datetime(2023, 12, 31)

    # Create Point for Lake Tahoe
    tahoe = Point(39.0001, -120.0001, 70)

    # adjust attributes fro tahoe
    tahoe.radius = 2000000
    tahoe.method = "weighted"

    # Get daily data for 2018
    df = Daily(tahoe, start, end)
    df = df.fetch()

    # convert all fields to farhenheit
    df = df.assign(MaxTemp=lambda x: (9 / 5) * x["tmax"] + 32)
    df = df.assign(MinTemp=lambda x: (9 / 5) * x["tmin"] + 32)
    df = df.assign(AvgTemp=lambda x: (9 / 5) * x["tavg"] + 32)
    return df


def plot_temp(df):
    # Plot daily temperature data
    fig = px.scatter(
        df, x=df.index, y=["AvgTemp", "MinTemp", "MaxTemp"], title="Daily Temperature in Tahoe"
    )
    # add trendline
    fig.update_traces(mode="lines+markers")
    fig.add_scatter(
        x=df.index, y=df["AvgTemp"].rolling(window=30).mean(), mode="lines", name="30 Day Avg"
    )
    fig.update_layout(
        title="Daily Temperature in Tahoe",
        xaxis_title="Date",
        yaxis_title="Temperature (F)",
        legend_title="Temperature",
    )
    path_html = "html/1.2.a_TahoeTemp.html"
    div_id = "1.3.d_Precip"
    fig.write_html(
        file=path_html,
        include_plotlyjs="directory",
        div_id=div_id,
    )


def plot_extremeheat(df):
    path_html = "html/1.2.a_ExtremeHeatDays.html"
    div_id = "1.3.d_Precip"
    color_sequence = ["#023f64"]
    hovertemplate = "%{y:,.0f} days over 85 F"
    format = ",.0f"
    tickvals = None
    ticktext = None
    tickangle = None
    hovermode = "x unified"
    config = {"displayModeBar": False}
    # create a dataframe with the number of extreme heat days
    extremeHeatDaysDF = df[df["MaxTemp"] > 85]
    extremeHeatDaysDF = extremeHeatDaysDF.assign(Count=1)
    extremeHeatDaysDF = extremeHeatDaysDF.resample("Y").sum()
    extremeHeatDaysDF = extremeHeatDaysDF.assign(Year=extremeHeatDaysDF.index.year)

    # plot the number of extreme heat days
    fig = px.bar(
        extremeHeatDaysDF,
        x="Year",
        y="Count",
        # title="Number of Extreme Heat Days in Tahoe (over 85 degrees F)",
        color_discrete_sequence=color_sequence,
    )

    # update layout
    fig.update_layout(
        yaxis=dict(title="Days"),
        xaxis=dict(title="Year", showgrid=False),
        hovermode=hovermode,
        template="plotly_white",
        dragmode=False,
    )

    fig.update_traces(hovertemplate=hovertemplate)
    fig.update_yaxes(tickformat=format)
    fig.update_xaxes(
        tickvals=tickvals,
        ticktext=ticktext,
        tickangle=tickangle,
    )
    # write figure to html
    fig.write_html(
        config=config,
        file=path_html,
        include_plotlyjs="directory",
        div_id=div_id,
    )
